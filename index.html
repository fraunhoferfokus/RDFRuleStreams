<!DOCTYPE html>
<html>
	<head>
		<title>Extension of the SPARQL Abstract Data Model for RDF Stream Processing</title>
		<meta charset="utf-8" />
		<script src="http://www.w3.org/Tools/respec/respec-w3c-common" async="async" class="remove"></script>
		<script class="remove">
      var respecConfig = {
          specStatus: "CG-DRAFT",
          shortName:  "rdf-stream-semantics",
          editors: [
            {
              name:       "Editor 1",
              company:    "Company 1",
              companyURL: "http://example1.com/",
              mailto: "ed1@example1.com"
            },
            {
              name:       "Editor 2",
              company:    "Company 2",
              companyURL: "http://example2.com/",
              mailto: "ed2@example1.com"
            }
          ],
          authors: [
            {
              name:       "Tara Athan",
              company:    "Athan Services",
              companyURL: "http://athant.com",
              mailto: "taraathan@gmail.com"
            },
            {
              name:       "Author 2",
              company:    "Company 2",
              companyURL: "http://example2.com/",
              mailto: "auth2@example1.com"
            }
          ],
          wg:           "RDF Stream Processing Community Group",
          wgURI:        "https://www.w3.org/community/rsp/",
          wgPublicList: "public-rsp",

          localBiblio:  {
            "LINEARCOMPOSITION": {
              title: "Multi-device Linear Composition on the Web: Enabling Multi-device Linear Media with HTMLTimingObject and Shared Motion",
              href: "https://sites.google.com/site/mediasynchronization/Paper4_Arntzen_webComposition_CR.pdf?attredirects=0&amp;d=1",
              authors: [
                "Ingar M. Arntzen",
                "Njål T. Borch",
                "François Daoust",
                "Dominique Hazaël-Massieux"
              ]
            },
            "BLOGIC": {
              title:    "Blogic",
              href:     "http://www.slideshare.net/PatHayes/blogic-iswc-2009-invited-talk",
              authors:  [
                "Pat Hayes"
              ]
            },
            "DUL": {
              title:    "DOLCE+DnS Ultralite (dul)",
              href:     "http://lov.okfn.org/dataset/lov/vocabs/dul",
              authors:  [
                "Aldo Gangemi"
              ]
            },
            "DVB-CSS": {
              title: "ETSI TS 103 256-2 V1.1.1 Digital Video Broadcasting (DVB); Companion Screens and Streams; Part 2: Content Identification and Media Synchronization",
              href: "http://www.etsi.org/modules/mod_StandardSearch/pdf.png"
            },
            "SHAREDMOTION": {
              title: "Shared Motion",
              href: "http://motioncorporation.com"
            },
            "MEDIASYNC":{
              title: "MediaSync",
              href: "https://github.com/webtiming/mediasync"
            },
            "SEQUENCER" : {
              title: "Open-source sequencer library",
              href: "https://github.com/webtiming/sequencer"
            }
          },
          otherLinks: [
            {
              key: "Version history",
              data: [
                {
                  value: "GitHub streamreasoning/RSP-QL/commits",
                  href: "https://github.com/streamreasoning/RSP-QL/commits/"
                }
              ]
            },
            {
              key: "Participate",
              data: [
                {
                  value: "GitHub streamreasoning/RSP-QL",
                  href: "https://github.com/streamreasoning/RSP-QL"
                },
                {
                  value: "File an issue",
                  href: "https://github.com/streamreasoning/RSP-QL/issues/new"
                },
                {
                  value: "Open issues",
                  href: "https://github.com/streamreasoning/RSP-QL/issues/"
                },
                {
                  value: "Mailing-list (public-rsp@w3.org)",
                  href: "https://lists.w3.org/Archives/Public/public-rsp/"
                }
              ]
            }
          ],

          issueBase: "https://github.com/streamreasoning/RSP-QL/issues/",
          githubAPI: "https://api.github.com/repos/streamreasoning/RSP-QL"
      };
    </script>
		<style type="text/css">
			table{
			    border-collapse: collapse;
			    border-style: hidden hidden none hidden;
			}
			table thead,
			table tbody{
			    border-bottom: solid;
			}
			table td,
			table th{
			    border-left: solid;
			    border-right: solid;
			    border-bottom: solid thin;
			    vertical-align: top;
			    padding: 0.2em;
			}</style>
	</head>
	<body>
		<!-- ABSTRACT -->
		<section id="abstract"> </section>
		<!-- STATUS OF DOCUMENT -->
		<section id="sotd">
			<p> The specification is intended for discussion within the RDF Stream Processing
				Community Group. Its content does not yet represent the consensus of the Community
				Group. </p>
			<p class="warning"> This specification is incomplete. </p>
		</section>
		<!-- INTRODUCTION -->
		<section class="informative" id="intro">
			<h2>Introduction</h2>
		</section>
		<section id="basics">
			<h2>The Basics</h2>
			<section id="namespaces-and-prefixes">
				<h3>Namespaces and Prefixes</h3>
				<p class="ednote">Do we need any new namespaces for this document? </p>
				<p>Additional prefixes used in this document are the following: </p>
				<div style="text-align: left;">
					<table class="thinborder" style="margin-left: auto; margin-right: auto;">
						<caption id="namespace-table">Table 1: Prefix and Namespaces used in this
							specification</caption>
						<tbody>
							<tr>
								<td><b>prefix</b></td>
								<td><b>namespace IRI</b></td>
								<td><b>definition</b></td>
							</tr>

							<tr>
								<td>rsp</td>
								<td><code>http://www.w3.org/ns/rsp#</code></td>
								<td>The RSP rnamespace</td>
							</tr>

							<tr>
								<td>rdf</td>
								<td><code>http://www.w3.org/1999/02/22-rdf-syntax-ns#</code></td>
								<td>The RDF namespace [[!RDF-SCHEMA]]</td>
							</tr>

							<tr>
								<td>rdfs</td>
								<td><code>http://www.w3.org/2000/01/rdf-schema#</code></td>
								<td>The RDFS namespace [[!RDF-SCHEMA]]</td>
							</tr>

							<tr>
								<td>xsd</td>
								<td><code>http://www.w3.org/2000/10/XMLSchema#</code></td>
								<td>XML Schema Namespace [[!XMLSCHEMA11-2]]</td>
							</tr>

							<tr>
								<td>owl</td>
								<td><code>http://www.w3.org/2002/07/owl#</code></td>
								<td>The OWL namespace [[!OWL2-OVERVIEW]]</td>
							</tr>

							<tr>
								<td>owl-time</td>
								<td><code>http://www.w3.org/2006/time#</code></td>
								<td>The OWL-TIME namespace [[!OWL-TIME]]</td>
							</tr>

							<tr>
								<td>prov</td>
								<td><code>http://www.w3.org/ns/prov#</code></td>
								<td>The PROV namespace [[!PROV-DM]]</td>
							</tr>

							<tr>
								<td>dul</td>
								<td><code>http://www.ontologydesignpatterns.org/ont/dul/DUL.owl#</code></td>
								<td>The DOLCE+DnS Ultralet namespace
									(http://lov.okfn.org/dataset/lov/vocabs/dul) [[DUL]]</td>
							</tr>

							<tr>
								<td>(others)</td>
								<td>(various)</td>
								<td>All other namespace prefixes are used in examples only. <br />
									In particular, IRIs starting with "http://example.com"
									represent<br /> some application-dependent IRI [[!IRI]]</td>
							</tr>
						</tbody>
					</table>
				</div>
			</section>
			<section id="constraints">
				<h3>Restrictions on SPARQL Query Language</h3> For simplicity, we use here a subset
				of the SPARQL Query language, with the aim to minimize ambiguity of semantics.
				Constraints are: <ol>
					<li>The Sample aggregation operator is not allowed either explicitly or
						implicitly.</li>
				</ol>
			</section>
		</section>
		<section id="data-structures">
			<h2>Data Structures</h2>
			<p>In this section, we review the data structure types defined in other recommendations
				and state the definitions of new data structure types that support the signature
				definitions of new algebra operators.s</p>
			<section id="existing-datastructuretypes">
				<h3>Existing Data Structure Types</h3>
				<p class="ednote">For now, I keep this table here as a summary of definitions and
					links to the recommendations for existing datatypes. In the final document, this
					table will be moved to an appendix, or deleted. </p>
				<p>We make use of the following data structure types from other specifications in
					the RDF and SPARQL family:</p>
				<div style="text-align: left;">
					<table class="thinborder" style="margin-left: auto; margin-right: auto;">
						<caption id="existing-data-structure-types-table"><b>Table A</b>: Existing
							data structure types used in this specification</caption>
						<tbody>
							<tr>
								<td><b>Data Structure Type</b></td>
								<td><b>Reference</b></td>
								<td><b>Definition</b>
								</td>
							</tr>
							<tr>
								<td><dfn>solution mapping</dfn></td>
								<td>[[!SPARQL11-Query]] <a
										href="https://www.w3.org/TR/2013/REC-sparql11-query-20130321/#sparqlSolutions"
										>#sparqlSolutions</a></td>
								<td> partial function μ : V -> RDF-T </td>
							</tr>
							<tr>
								<td><dfn>multiset of solution mappings</dfn></td>
								<td>[[!SPARQL11-Query]] <a
										href="https://www.w3.org/TR/2013/REC-sparql11-query-20130321/#BasicGraphPattern"
										>#BasicGraphPattern</a></td>
								<td>A multiset is an unordered collection of elements in which each
									element may appear more than once. It is described by a set of
									elements and a cardinality function giving the number of
									occurrences of each element from the set in the multiset. </td>
							</tr>
							<tr>
								<td><dfn>sequence of solution mappings</dfn></td>
								<td>[[!SPARQL11-Query]] <a
										href="https://www.w3.org/TR/2013/REC-sparql11-query-20130321/#solutionModifiers"
										>#solutionModifiers</a>
								</td>
								<td>The recommendation does not define the concept of "sequence", so
									it is not normatively limited. </td>
							</tr>
							<tr>
								<td><dfn data-lt="RDF triples|triple|triples">RDF triple</dfn></td>
								<td>[[!RDF11-Concepts]] <a
										href="https://www.w3.org/TR/rdf11-concepts/#section-triples"
										>#section-triples</a>
								</td>
								<td>An RDF triple consists of three components: <ul>
										<li>the <dfn id="dfn-subject">subject</dfn>, which is an
												<a><abbr
												title="Internationalized Resource Identifier"
												>IRI</abbr></a> or a <a>blank node</a></li>

										<li>the <dfn id="dfn-predicate">predicate</dfn>, which is an
												<a>IRI</a></li>

										<li>the <dfn id="dfn-object">object</dfn>, which is an
												<a>IRI</a>, a <a>literal</a> or a <a>blank
											node</a></li>
									</ul>
								</td>
							</tr>
							<tr>
								<td><dfn data-lt="RDF Graphs|graph|graphs">RDF Graph</dfn></td>
								<td>[[!RDF11-Concepts]] <a
										href="https://www.w3.org/TR/rdf11-concepts/#section-rdf-graph"
										>#section-rdf-graph</a>
								</td>
								<td>An RDF graph is a set of RDF triples. </td>
							</tr>
							<tr>
								<td><dfn data-lt="RDF Datasets|RDF 1.1 Dataset|RDF 1.1 Datasets">RDF
										dataset</dfn></td>
								<td>[[!RDF11-Concepts]] <a
										href="https://www.w3.org/TR/rdf11-concepts/#section-dataset"
										>#section-dataset</a>
								</td>
								<td>An RDF dataset is a collection of <a>RDF graphs</a>, and
									comprises: <ul>
										<li>Exactly one <dfn data-lt="default graphs">default
												graph</dfn>, being an <a>RDF graph</a>. The default
											graph does not have a name and MAY be empty.</li>
										<li>Zero or more <dfn data-lt="named graph">named
												graphs</dfn>. Each named graph is a pair consisting
											of an IRI or a blank node (the <dfn>graph name</dfn>),
											and an <a>RDF graph</a>. Graph names are unique within
											an RDF dataset.</li>
									</ul>
								</td>
							</tr>
							<tr>
								<td><dfn data-lt="RDF Streams">RDF Stream</dfn></td>
								<td><b>Reference</b></td>
								<td><b>Definition</b>
								</td>
							</tr>
							<tr>
								<td><dfn>RDF Surface (sensu Pat Hayes)</dfn></td>
								<td><b>Reference</b></td>
								<td><b>Definition</b>
								</td>
							</tr>
						</tbody>
					</table>
				</div>
				<p class="note">In mathematics, the "cardinality" (typically called "multiplicity")
					mapping of multisets is generally assumed to range over non-negative integers.
					The cardinality of a multiset is, typically, defined as the sum of the
					multiplicities of all its elements. </p>
				<p class="ednote">This information may or may not be relevant: Note that not all
					sequences can be converted (by forgetting the order) to multisets with finite
					cardinality; some sequences would correspond to multisets with countable
					cardinality (where cardinality of an element may be a non-negative integer or
					the cardinal number aleph-nought). All multisets with countable cardinality can
					be expressed as sequences. However, not all multisets with countable cardinality
					can be expressed as ordered sequences. SPARQL implicitly assumes sequences of
					solution mappings may be ordered, and hence we may suppose that the intention is
					to use only sequences with finite replication of any value, corresponding to
					multisets with finite cardinality when order is forgotten. </p>
			</section>
			<section id="def-datasets">
				<h3>RDF Datasets</h3>
				<section id="def-rdf-dataset">
					<h3>RDF Dataset</h3>
					<p>Recall that an <a>RDF dataset</a> is a collection of <a>RDF graphs</a>, and
						comprises:</p>
					<ul>
						<li>Exactly one <a>default graph</a>.</li>
						<li>Zero or more <a>named graphs</a>.</li>
					</ul>
					<p>We generalize this concept below to accommodate more complex structures.</p>
				</section>
				<section id="def-k-th-order-static-data-structure">
					<h4>k-th Order Static RDF Data Structures</h4>
					<p>A <dfn
							data-lt="k-th order static RDF data structures|k-th order static data structure|k-th order static data structures|static data structure|static data structures"
							>k-th order static RDF data structure</dfn> is a <a>data structure</a>
						that is defined inductively as follows.</p>
					<ul>
						<li>A <dfn>zeroth-order static data structure</dfn> is an RDF Graph. </li>
						<li>A (k+1)-th order static data structure is a collection of data
							structures of k-th order or less consisting of: <ul>
								<li>an optional distinguished <a>data structure</a>, called the
										<dfn>default part</dfn> of the static data structure, of
									order k or less. </li>
								<li>one or more <a>named k-th order data structures</a>. The names
									of the named data structures are unique within the static data
									structure. The data structure consisting of only these named
									data structures is called the <dfn>named part</dfn> of the data
									structure. </li>
							</ul>
						</li>
					</ul>
					<p>An RDF Graph is the only <a>static data structure</a> that has no named part,
						and is equal to its default part.</p>
					<p>A named graph is a first-order <a>static data structure</a>. It has no
						default part and is equal to its named part.</p>
					<p>An RDF dataset, as defined in [[!RDF-Concepts]] is either a zeroth- or
						first-order <a>static data structure</a>. It always has a default part, its
						default graph, which may be the empty graph. If it contains at least one
						named graph, then it has a named part and its order is 1.</p>
					<p>A <dfn data-lt="timestamped graphs">timestamped graph</dfn> is defined in
							@@@<a href="">RDF Stream Abstract Syntax and Semantics</a> as an RDF
						dataset with one named graph and a distinguished triple, the timestamp
						triple, in its default graph having the name of the named graph as its
						subject. A timestamped graph may be emulated by a dataset of second order or
						less, as described in Section <a
							href="#def-rdf-stream-as-second-order-store"></a></p>
					<p>We define a number of syntactic operations on <a>static data structures</a>
						as follows. Let DS be a <a>static data structure</a> and E be an arbitrary
						entity. </p>
					<ul>
						<li><dfn>isStatic</dfn>(E) is true if E is a <a>static data structure</a>;
							otherwise it is false.</li>
						<li><dfn>hasDefault</dfn>(DS) is true if DS has a default part; otherwise,
							it is false.</li>
						<li><dfn>hasNamed</dfn>(DS) is true if DS has a named part; otherwise, it is
							false.</li>
						<li><dfn>defaultPart</dfn>(DS) is defined on all static data structures that
							have a default part (hasDefault(DS) is true); otherwise it is undefined.
							When defined, its value is the default part of DS.</li>
						<li><dfn>named</dfn>(DS) is defined on all static data structures that have
							a named part (hasNamed(DS) is true); otherwise it is undefined. When
							defined, its value is the named part of DS.</li>
						<li><dfn>names</dfn>(DS) is defined on all <a>static data structures</a>. If
								<a>hasNamed</a>(DS) is true, then its value is the set of names of
							the named data structures in DS; otherwise, its value is the empty
							set.</li>
						<li>Every static data structure DS has a well-defined order, a non-negative
							integer, and this is the value of the function
							<dfn>order</dfn>(DS).</li>
						<li><dfn>isNamed</dfn>(DS) is true if DS is a <a>named data structure</a>;
							otherwise, it is false. In this case, the cardinality of
							<a>names</a>(DS) is 1, <a>hasDefault</a>(DS) is false,
							<a>hasNamed</a>(DS) is true, and DS = <a>named</a>(DS).</li>
						<li>If <a>isNamed</a>(DS) is true, then <dfn>name</dfn>(DS) is its
							name.</li>
						<li>If n is a member of names(DS), then <dfn>content</dfn>(n, DS) is defined
							as the content of the named data structure in named(DS) having the name
							n; otherwise, it is defined as the empty set. If <a>isNamed</a>(DS) is
							true, then we define <dfn>content(DS)</dfn> = content(name(DS),
							DS).</li>
						<li><dfn>nameMap(DS)</dfn> is the function defined on names(DS) that maps
							name to content(name, DS).</li>
						<li>A static data structure DS with order k &gt; 0 is uniquely determined by
							the following properties: default(DS), names( DS), and the value of
							content(name, DS) for each name in names(DS). Therefore we may define a
							constructor that takes this set of properties as input parameters and
							returns the corresponding static data structure. Let this constructor be
							called <dfn>Static<sub>k</sub></dfn> with domain DS<sub>&lt; k-1</sub> x
								2<sup>Names</sup> x PartialFunctions(Names => DS<sub>&lt; k-1</sub>)
							where DS<sub>&lt; k-1</sub> is the set of data structures of order k-1
							or less.</li>
					</ul>
					<aside class="example"><p>The constructor <a>Static<sub>k</sub></a> can be used
							to (abstractly) create a <a>named data structure</a> as follows.</p>
						<p>Let DS be <a>data structure</a> of order k-1 or less, and set ND =
								Static<sub>k</sub>({}, {n}, {n => DS }). Then isNamed(ND) is true,
							names(ND) = {n}, name(ND) = n, content(n, ND) = DS, and order(ND) =
							k.</p>
					</aside>
					<aside>The concrete syntax for building a static data structure depends on the
						extension of Update Operations, e.g. the <a>OpInsertData</a> Update
						Operation, and the extension of the <a>pattern</a> syntax to express k-th
						order patterns, including k-th order named patterns.</aside>
				</section>
				<section id="def-kth-order-dataset">
					<h4>k-th order RDF Dataset</h4>
					<p>A <dfn
							data-lt="k-th Order RDF Datasets|k-th Order Dataset|k-th Order Datasets|Dataset|Datasets"
							>k-th Order RDF Dataset</dfn> is a <a>k-th order static data
							structure</a> DS with the following properties. </p>
					<ul>
						<li>If k &gt; 0, then <a>defaultPart</a>(DS) is a <a>dataset</a> of order
							k-1 or less.</li>
						<li>For every n in <a>names</a>(DS), <a>content</a>(n, DS) is a
								<a>dataset</a> of order k-1 or less.</li>
					</ul>
					<p class="note">Every RDF Graph is a zeroth-order RDF dataset, and every
						zeroth-order RDF dataset is an RDF Graph.</p>
					<p class="note"> A first-Order RDF Dataset is an RDF Dataset according to the
						definition in [[!RDF11-Concepts]]. However not every RDF Dataset, in the
						sense of [[!RDF11-Concepts]], is a first-order <a>dataset</a>, because it
						may have zero named graphs. In that case it is a zeroth-order
						<a>dataset</a>. </p>
					<p class="note"> Hereafter in this document, "dataset", without modification,
						means a <a>k-th Order RDF Dataset</a> for arbitrary k. When the original
						concept of RDF Dataset is intended, we use the term <a>RDF 1.1 Dataset</a>
						for clarity. </p>
					<p class="ednote">To be clarified in a separate semantics section: just as there
						is not a single recommended semantics for RDF 1.1 Datasets, it is important
						to be inclusive regarding possible semantics for k-th Order RDF Datasets. An
						important consideration is whether the component Named Datasets lie on a
						single <a>RDF Surface (sensu Pat Hayes)</a>, i.e. do they share blank nodes. </p>
					<p>A <dfn
							data-lt="Named k-th Order RDF Datasets|Named Dataset|Named Datasets|Named k-th Order Dataset|Named k-th Order Datasets"
							>Named k-th Order RDF Dataset</dfn> is a named <a>static data
							structure</a> whose content is a <a>k-th order dataset</a>.</p>
					<p class="note"> Hereafter in this document, <a>named dataset</a>, without
						modification, means a <a>named k-th Order RDF dataset</a> where k is not
						specified. </p>
					<p>We define syntactic operations on <a>datasets</a> as follows. Let E be an
						arbitrary entity. </p>
					<ul>
						<li><dfn>isDataset</dfn>(E) is true if E is a <a>dataset</a>; otherwise it
							is false.</li>
					</ul>
					<p class="note">The constructor <a>Static<sub>k</sub></a> defined for general
						static data structures works as well for <a>datasets</a> of arbitrary
						order.</p>
					<p class="ednote">We need an extension of the content operation to sets of
						names, but it depends on the extension of Dataset-UNION to k-th order
						datasets and to sets of arguments. </p>
					<p>If N is a set of names and DS is a <a>k-th order dataset</a>, then
							<dfn>content-UNION</dfn>(N, DS) is defined as
						<a>Dataset-UNION</a>({content(n, DS)|n is in N}) .</p>
					<p class="ednote">All these functions need to be added to the table of
						structural inferences.</p>
				</section>
			</section>
			<section id="def-data-sequences-structures">
				<h3>RDF Data Sequences and Structures</h3>
				<section id="def-data-sequences">
					<h4>RDF Data Sequences</h4>
					<p>An <dfn data-lt="RDF Data Sequences|Data Sequence|Data Sequences">RDF Data
							Sequence</dfn> is a <a>sequence</a> of <a>data structures</a>.</p>
					<p>In this document, we use the term <dfn>sequence</dfn> in the sense of a
						totally-ordered set (in mathematics, called a chain) that can be strictly
						monotonically mapped onto the integers. I.e., it is isomorphic, as a poset,
						to a subset of the integers. A sequence may be finite, or infinite. If
						infinite, the set MAY or MAY NOT have a least element, and MAY or MAY NOT
						have a greatest element. If a sequence has neither least nor greatest
						element, then it is said to be <dfn>bi-infinite</dfn>.</p>
					<p>We define a number of syntactic operations on <a>data sequences</a> as
						follows. Let DSQ be a <a>data sequence</a>. </p>
					<ul>
						<li><dfn>isSequence</dfn>(E) is true if E is a <a>data sequence</a>;
							otherwise it is false.</li>
						<li>If DST is an element of DSQ, then <dfn>isMemberOf</dfn>(DST, DSQ) is
							true; otherwise, it is false.</li>
						<li>If DST and DST' are two elements of DSQ, then <dfn>previousTo</dfn>(DST,
							DST'; DSQ) is defined; otherwise it is undefined. It has the value true
							if DST &lt; DST' in the context of DSQ, and has the value false if DST
							&gt;= DST' in the context of DSQ. </li>
						<li>If <a>previousTo</a>(DST, DST'; DSQ), then <dfn>follows</dfn>(DST, DST';
							DSQ) is defined; otherwise it is undefined. It has the value true if DST
							&gt; DST' in the context of DSQ, and has the value false if DST &lt;=
							DST' in the context of DSQ. </li>
						<li>If DSQ has a least element then <dfn>hasLeast</dfn>(DSQ) has the value
							true, and otherwise false </li>
						<li>If DSQ has a greatest element then <dfn>hasGreatest</dfn>(DSQ) has the
							value true, and otherwise false. </li>
						<li>If <a>hasLeast</a>(DSQ) is true, then <dfn>least</dfn>(DSQ) is defined,
							and has the value of the least element of DSQ. Otherwise it is
							undefined. </li>
						<li>If <a>hasGreatest</a>(DSQ) is true, then <dfn>greatest</dfn>(DSQ) is
							defined, and has the value of the greatest element of DSQ. Otherwise it
							is undefined. </li>
						<li>If <a>least</a>(DSQ) = DST, then <dfn>isLeastOf</dfn>(DST, DSQ) has
							value true, and otherwise false. </li>
						<li>If <a>greatest</a>(DSQ) = DST, then <dfn>isGreatestOf</dfn>(DST, DSQ)
							has value true, and otherwise false. </li>
						<li>If <a>isLeastOf</a>(DST, DSG) is false, then <dfn>predecessor</dfn>(DST;
							DSQ) is defined, and has the value of the unique <a>predecessor</a> of
							DST in the context of DSQ. I.e., if predecessor(DST; DSQ) = DST', then
							(in the context of DSQ) DST' &lt; DST, and for any DST'' where DST''
							&lt; DST, it holds that DST'' &lt;= DST'. </li>
						<li>If <a>isGreatestOf</a>(DST, DSQ) is false, then
							<dfn>successor</dfn>(DST; DSQ) is defined, and has the value of the
							unique <a>successor</a> of DST in the context of DSQ. I.e., if
							successor(DST; DSQ) = DST', then (in the context of DSQ) DST' &gt; DST,
							and for any DST'' where DST'' &gt; DST, it holds that DST'' &gt;= DST'. </li>
						<li>The basic constructor operation <dfn>Cons</dfn> builds sequences by
							adding an additional element to a sequence with a greatest element. The
							basic operation analagous to a "head" function is <a>greatest</a>, that
							returns the greatest element if it exists. We define also the basic
							operation <dfn>exceptGreatest</dfn>, which is the counterpart to the
							traditional "tail" function. </li>
						<li>Square brackets are used in the abstract syntax to define a sequence
							explicitly, with the greatest element first. </li>
					</ul>
					<aside class="example"> In the case that <a>hasGreatest</a>(DSQ) is true, then
							<p> Cons( greatest(DSQ), exceptGreatest(DSQ) ) = DSQ.</p>
					</aside>
					<aside> The empty sequence, [], is also denoted S<sub>0</sub>.</aside>
					<aside class="example">For any data structure DS, <p>Cons(DS, S<sub>0</sub>) =
							[DS]</p></aside>
					<aside>A Graph Store in the sense of [[!SPARQL11-Update]] is most closely
						related, of the <a>data structures</a> considered in this document, to a
							<a>data sequence</a> where each element is a <a>dataset</a> of first
						order or less. </aside>
					<p>In the spirit of [[!SPARQL11-Update]], we define the <dfn>Revise</dfn>
						operation as an explicit operation acting on a <dfn>terminated data
							sequence</dfn> (i.e a <a>data sequence</a> where <a>hasGreatest</a> is
						true) that applies a binary function to the greatest element of the
						sequence, and to the sequence itself, and <a>Cons</a>es it onto the
						sequence.</p>
					<aside class="example">Consider a Graph Store which has been newly initialized
						as the empty graph <p>GS = Cons({}, S<sub>0</sub>)</p>
						<p>The application of <a>Revise</a> to this graph store with an OpInsertData
							operation specification as a lambda expression is expressed as follows. </p>
						<p>GS' = Revise(GS, (λxy.OpInsertData(P, {}, x, y)) ) <br /> =
							Cons(OpInsertData(P, {}, greatest(GS), GS), GS) <br /> where P is a
							ground Quadpattern.</p>
						<p>An additional update to this graph store to insert data according to
							another ground quadpattern P' would be expressed as follows.</p>
						<p>GS'' = Revise(GS', (λxy.OpInsertData(P', {}, x, y)) ) <br /> =
							Cons(OpInsertData(P', {}, greatest(GS'), GS'), GS').</p>
						<p>Note that by the definition of OpInsertData in [[!SPARQL11-Update]], any
							blank node appearing in P' that also appears in P must be renamed.</p>
					</aside>
					<p class="ednote">Add to table of structural inferences: rdfsq:isMemberOf,
						rdfsq:previousTo, rdfsq:follows, rdfsq:hasLeast, rdfsq:hasGreatest,
						rdfsq:least, rdfsq:greatest, rdfsq:isLeastOf, rdfsq:isGreatestOf,
						rdfsq:predecessor, rdfsq:successor, These relationships can be inferred, but
						only within the context of a particular sequence. The order is not an
						inherent relationship between the two data structures. That means that if
						this information is materialized, it must be done, in a number of cases, as
						a quad, to indicate the context in which it holds. The graph name in the
						quad may or may not "denote" the sequence, depending on the semantics that
						is in play. The sequence does not need to be named explicitly, but can be
						indicated by a blank node, (again, provided that makes sense within the
						active semantics). If the sequence is a named sequence, then whether it is
						appropriate to use that name to materialize such statements depends on the
						active semantics.</p>
				</section>
				<section id="def-k-th-order-data-structure">
					<h4>k-th Order RDF Data Structure</h4>
					<p>A <dfn
							data-lt="k-th Order RDF Data Structures|k-th Order Data Structure|k-th Order Data Structures|Data Structure|Data Structures"
							>k-th Order RDF Data Structure</dfn> is defined by cases as follows. </p>
					<p>A k-th order RDF data structure is a collection of k-th order static data
						structures </p>
					<ul>
						<li>The optional <dfn>static part</dfn> of DS is a k-th order static data
							structure.</li>
						<li>The <dfn>dynamic part</dfn> of DS, which is optional if DS has a static
							part, is a sequence of k-th order static data structures.</li>
					</ul>
					<p>A <dfn
							data-lt="named k-th order data structure|named data structure|named data structures"
							>named k-th order data structures</dfn> is a k+1-th order <a>static data
							structure</a> that is an ordered tuple [n, DS, k] where n is the name of
						the named data structure and data structure DS, of order k or less, is the
						content of the named data structure. </p>
					<p class="ednote">The third argument should be optional; otherwise, a named
						graph is not actually a named data structure. If the third argument is not
						given, then the order of the named data structure is one more than the order
						of its content. </p>
					<p class="ednote">There is another way to accomplish the same effect as the
						third argument, using the reserved name DEFAULT. Let G be a graph. A
						conventional named graph is DS1 = [n, G], a first-order data structure. DS2
						= [n, G, 1] is a second-order data structure. So, instead of [n, G, 1], we
						could write DS2 = [n, [DEFAULT, G]] to construct a second-order data
						structure. Note that the content of DS2 would still be G, a zeroth-order
						data structure. The syntax [DEFAULT, G] as a stand-alone term would have to
						be disallowed, as it is not a named graph.</p>
					<p class="ednote">A third way to define named structures is in a more vague way
						than this, similar to the other definitions, where we don't refer to a
						particular structure (set, tuple, etc.) except in special cases.. In this
						approach, a named data structure ND is simply a static data structure, of
						order 1 or more, for which <a>isNamed</a>(ND) is true. It is required that
							<a>hasDefault</a>(ND) is false, <a>hasNamed</a>(ND) is true, DS =
							<a>named</a>(DS), and <a>names</a> is a set with one member, that member
						being equal to name(DS). Letting contents(DS) = contents(name(DS),DS), then
						it further holds that order(contents(DS)) &lt; order(DS). When
						<a>order</a>(ND) = order(contents(ND))+1, then ND <i>is</i> a pair,
						[name(ND), contents(ND)]. When order(ND) = 1, then ND <i>is</i> a named
						graph.</p>
					<p class="note">Because <a>named data structures</a> are by definition <a>static
							data structures</a>, then all functions defined on static data
						structures are defined on named data structures.</p>
					<p class="note">The third argument of the tuple of a named data structure
						determines the order of the structure: <a>order</a>([n, DS, k]) = k+1 .</p>
					<p>We define a number of syntactic operations on <a>data structures</a> as
						follows. Let DS be a <a>data structure</a>. </p>
					<ul>
						<li><dfn>isDataStructure</dfn>(E) is true if E is a <a>data structure</a>;
							otherwise it is false.</li>
						<li><dfn>hasStatic</dfn>(DS) is true if DS has a static part; otherwise, it
							is false.</li>
						<li><dfn>hasDynamic</dfn>(DS) is true if DS has a dynamic part; otherwise,
							it is false.</li>
						<li><dfn>staticPart</dfn>(DS) is defined on all data structures that have a
							static part (hasStatic(DS) is true); otherwise it is undefined. When
							defined, its value is the static part of DS.</li>
						<li><dfn>dynamicPart</dfn>(DS) is defined on all data structures that have a
							dynamic part (hasDynamic(DS) is true); otherwise it is undefined. When
							defined, its value is the dynamic part of DS.</li>
					</ul>
					<p class="note">If a k-th order <a>data structure</a> has no dynamic part, then
						its static part is itself (staticPart(DS) = DS). In that case it is a k-th
						order <a>static data structure</a>, e.g. an RDF graph (k=0) or k-th order
							<a>dataset</a>.</p>
					<p class="note">If a k-th order data structure DS does not have a static part,
						then dynamicPart(DS) = DS; in this case, the data structure is a <a>data
							sequence</a>. In particular, it is a sequence of k-th order <a>static
							data structures</a>. We define this special case of <a>data sequence</a>
						to be a <dfn>k-th order data sequence</dfn>.</p>
					<p>We extend the functions defined earlier on static data structures to data
						structures where <a>hasStatic</a> is true according to the following
						example: <a>names</a>(DS) = <a>names</a>(<a>staticPart</a>(DS)), and so
						on.</p>
					<p class="ednote">I have reverted to the terminology "static" and "dynamic"
						because using "unordered" and "ordered" has a collision with the "order" of
						the structure. However this terminology is not entirely satisfactory, for
						two reasons. One is that it suggests a temporal character, and while that is
						the primary motivation for these structures, the temporal nature comes from
						the semantics, not the sequential order. The sequential order could quite
						reasonably be exploited for nontemporal aspects that have ordering. The
						second reason it is unsatisfactory is that the "static" part can have either
						default or named parts that are "dynamic". This is particularly relevant in
						the case of the "store" structure, defined below, whose static part is a
						collection of repositories. Alternative: "map" and "history"?</p>
				</section>
			</section>
			<section id="def-repositories">
				<h3>RDF Repositories</h3>
				<section id="def-kth-order-rdf-repository">
					<h4>k-th Order RDF Repositories</h4>
					<p>A <dfn
							data-lt="k-th Order RDF Repositories|k-th Order Repository|k-th Order Repositories|RDF Repository|RDF Repositories|repository|repositories"
							>k-th Order RDF Repository</dfn> is a special case of <a>k-th order RDF
							data structure</a> that is defined by the following cases. </p>
					<ol>
						<li>A zeroth-order RDF Repository is a zeroth-order <a>dataset</a>. </li>
						<li>A k+1-th Order RDF Repository, k = 0, 1, ..., has a <a>dataset</a> of
							k-th order or less for its static part and an optional non-empty <a>data
								sequence</a> of <a>named k-th order datasets</a> for its dynamic
							part. The names of the datasets in this sequence are unique. Further,
							the contents of adjacent named datasets in the sequence are
							distinct.</li>
					</ol>
					<p class="note">A k-th Order RDF Repository may be viewed as a k-th Order RDF
						Dataset with the additional structure of a total order on its <a>named
							datasets</a>. However, the additional requirements on adjacent contents
						being distinct emphasizes the motivation of this definition as a model of a
						mutable dataset, where each element of the sequence describes a named
						"snapshot" of the dataset.</p>
					<p class="ednote">To be clarified in Eval section: The static part of the
						repository plays the role of background knowledge, which is unioned with
						every snapshot prior to query.</p>
					<p>Let R be a k-th order repository.</p>
					<p>Each element of the dynamic part of R is called a <dfn>version</dfn> of R.
						The function <dfn>isVersionOf</dfn>(U, R) is defined for all entities U, and
						is true exactly when <a>isMemberOf</a>(U, dynamicPart(R)) is true. </p>
					<p class="ednote">As written, a <a>version</a> is a named dataset. It may seem
						more intuitive to refer to the content of that named dataset as the version.
						However, it is quite possible for two (non-adjacent) versions to have the
						same content (i.e. a rollback). If we used only the content as the version,
						then it would not be clear which of these versions we were referring to.</p>
					<p>We say a version U is a <dfn>previous version</dfn> of version V in the
						context of R if <a>previousTo</a>(U, V; dynamicPart(R)) is true, and
						similarly V is called a <dfn>following version</dfn> of U in the context of
						the repository. The function <dfn>isPreviousVersionTo</dfn>(U, V; R) is
						defined whenever U and V are versions of R (<a>isVersionOf</a>(U, R) =
						isVersionOf(V, R) = true), and has the value <a>previousTo</a>(U, V;
						dynamicPart(R)); otherwise, it is undefined.</p>
					<p>An <dfn>initial version</dfn> of a repository is a version that does not have
						a previous version. A repository MAY have an initial version.</p>
					<p> The function <dfn>hasInitialVersion(R)</dfn> is defined and has the value of
							<a>hasLeast</a>(<a>dynamicPart</a>(R)). </p>
					<p class="note">If the dynamic part of a repositoriy has an initial version,
						then it is unique, due to the order being total; further, it is a minimal
						element of the dynamic part. </p>
					<p>If R has an initial version, then the function <dfn>initialVersionOf</dfn>(R)
						= <a>least</a>(dynamicPart(R)) is defined.</p>
					<p>If V is a version of R that is not an initial version, then we define the
							<dfn>preceding version</dfn> of V in the context of R to be the
							<a>predecessor</a> of version V in the dynamic part of repository R. The
						function <dfn>precedingVersion</dfn>(V; R) = <a>predecessor</a>(V;
							<a>dynamicPart</a>(R)) is defined for all non-intial versions V of R;
						otherwise, it is undefined. </p>
					<p>Similarly, we define the concepts of <dfn>terminal version</dfn>,
							<dfn>succeeding version</dfn>, and functions
							<dfn>hasTerminalVersion</dfn>, <dfn>terminalVersionOf</dfn>, and
							<dfn>succeedingVersion</dfn>.</p>
					<p class="ednote">Here is where it appears to be important to use the named
						dataset as the version, or to refer to version by name rather than by
						content. Because the same content can be associated with more than one
						version name in the same repository, so the preceding version of that
						content would not be uniquely defined.</p>
					<p>We say that each non-initial version <dfn>revises</dfn> its preceding
						version. We define <dfn>revises(U, V; R)</dfn> for all versions U and V of
						R, with the value true whenever V=<a>precedingVersion</a>(U; R); otherwise,
						it is false. </p>
					<p class="note">Because of the requirement for total order in the dynamic part,
						version structures do not branch.</p>
					<p> The dynamic part MAY be finite, semi-infinite, or bi-infinite.</p>
					<p>The ordered set of version names of a repository R is denoted by
							<dfn>versionNames</dfn>(R). </p>
					<p>The function <dfn>isVersionNameOf</dfn>(n, R) is true if n is a member of
							<a>versionNames</a>(R); otherwise, it is false.</p>
					<p>The function <dfn>versionContent</dfn>(n; R) is defined provided
							<a>isVersionNameOf</a>(n, R) is true, with value being the element (a
						named k-th order dataset) of the dynamic part of R having name n. Otherwise,
						the function is undefined.</p>
					<p>The function <dfn>hasNext</dfn>(n; R) is true provided n is the name of a
						non-terminal <a>version</a> of R (<a>isVersionNameOf</a>(n, R) is true and
							<a>terminalVersionOf</a>(R) &ne; <a>version</a>(n; R)). </p>
					<p>The function <dfn>next</dfn>(n; R) is defined provided <a>hasNext</a>(n; R)
						is true, and has the value <a>name</a>( <a>succeedingVersion</a>(
							<a>version</a>(n; R) ) ).</p>
					<p class="ednote">Redefine the functions hasNext and next in terms of the
						ordered set of version names. Then it is not necessary to have the function
						version(n;R).</p>
					<p>We define a Repository Constuctor as a basic operation
								<dfn>Repository<sub>k</sub></dfn>, k = 1, 2, ..., that takes the
						following arguments.</p>
					<ol>
						<li>The <a>dataset</a> of order k-1 or less that is the static part of the
							repository.</li>
						<li>The ordered set of version names of the repository. </li>
						<li>The mapping from the set of version names to <a>datasets</a> of order
							k-1 or less that defines the versions of the repository. </li>
					</ol>
					<p>To satisfy the definition of <a>repository</a>, an additional requirement is
						that the contents of adjacent versions MUST be distinct. Therefore, the
								<a>Repository<sub>k</sub></a> constructor carries out a
						reconciliation step that removes any version whose content is identical to
						that of its preceding version. This reconciliation may reduce the set of
						version names, in case of such version duplication.</p>
					<p>We further define a basic operation <dfn>Append2Repository</dfn> as
						follows.</p>
					<p>The arguments of <a>Append2Repository</a><sub>k</sub> are</p>
					<ol>
						<li>The input repository to be modified, or a dataset of order (k-1)
							representing the static part of an "empty" repository with no
							versions.</li>
						<li>The new repository version name, which must be distinct from version
							names of the input repository, if any.</li>
						<li>The dataset of order (k-1) or less that is to be the content of the new
							repository version.</li>
						<li>An <a>Append2Repository</a> operation cannot be vacuous; the contents of
							the new repository version must be different than the contents of the
							preceding version (i.e. the terminal version of the input
							repository).</li>
					</ol>
					<p class="ednote">To be clarified in the section on the extension of Eval to
						repositories: there is an entailment regime, called e.g. "provenance
						entailment regime", that has additional entailments beyond those of the
						simple entailment regimes in that the name of each non-initial version is
						related to the name of its previous version by the <a
							href="https://www.w3.org/TR/2012/WD-prov-o-20120503/#wasRevisionOf"
							>prov:wasRevisionOf</a> property. </p>
					<p class="ednote">To be clarified in the section on the extension of Eval to
						repositories: An objective for the provenance entailment regime is that it
						be monotonic with respect to repository updates. From this perspective, it
						would also be ok to include entailment regarding the initial version.
						Therefore, we define a new property <code>repo:isInitialVersion</code> that
						relates each version name of a repository to a boolean literal value. </p>
					<p class="ednote">This is not yet a sufficient analysis of the similarities and
						differences between a second-order repository and a Graph Store. Move to
						Examples section? A second-order <a>RDF Repository</a> is similar to a Graph
						Store, but with the additional structure that every version is named (albeit
						the name may be a blank node). </p>
					<p class="ednote">Needs more explanation, examples: Where Update Operations are
						conceived as functional specifications for transitions of the state of a
						Graph Store, for a RDF Repository these operations play the role of helper
						functions used in the "lazy" construction of the RDF Repository. </p>
					<p class="ednote">Needs more explanation, examples: To use a second-order
							<a>repository</a> to emulate a <a>Graph Store</a>, the input for query
						and update operations would have to be limited to some "current
							<a>version</a>", and the <a>static part</a> of the repository would be
						empty. The execution of an <a>Update operation</a> would move the "current
							<a>version</a> pointer" to the <a>succeeding version</a>. </p>
				</section>
				<section id="def-named-kth-order-repository">
					<h4>Named k-th Order RDF Repository</h4>
					<p>A <dfn
							data-lt="Named k-th Order RDF Repositories|Named RDF Repository|Named RDF Repositories|Named Repository|Named Repositories"
							>Named k-th Order RDF Repository</dfn> is a <a>named data structure</a>
						whose content is a <a>k-th order repository</a>. </p>
					<p class="ednote">To be clarified in the section on the extension of Eval on
						named repositories: Under the provenance entailment regime a <a>named RDF
							repository</a> has additional entailments that the name of each version
						is related to the name of the parent RDF Repository by the <a
							href="https://www.w3.org/TR/2012/WD-prov-o-20120503/#specializationOf"
							>prov:specializationOf</a> property. </p>
					<p class="ednote">To be clarified in the section on the extension of Eval to
						named repositories: For a named repository, e.g. within a store, the
						provenance entailment regime also includes an additional property,
							<code>repo:isInitialVersionOf</code>, with object being the name of the
						repository. A new namespace (prefix "repo") needs to be defined. These
						properties can be used to define operations on <a>data sequences</a> and
							<a>data structures</a> that extract parts of the sequence (e.g.
						foot(initial version), and subsequences related to that, such as the first
						10 versions) that are monotonic relative to update operations. </p>
					<p class="ednote">To be clarified in the section on the extension of Eval to
						repositories and named repositories: a "repository structure entailment
						regime" could be defined as an extension of the monotonic provenance
						entailment regime, relaxing the requirement for monotonicity with respect to
						update operations. This regime could then include entailments regarding the
						terminal version, using <code>repo:isTerminalVersion</code> and
							<code>repo:isTerminalVersionOf</code>. These properties could be used as
						the basis for basic operations on <a>data sequences</a> and <a>data
							structures</a> that extract parts of the sequence, e.g. head, tail and
						subsequences related to these) that are nonmonotonic relative to update
						operations). </p>
				</section>
			</section>
			<section id="def-stores">
				<h3>Stores</h3>
				<section id="def-kth-order-store">
					<h4>k-th Order RDF Store</h4>
					<p>A <dfn
							data-lt="k-th Order RDF Stores|k-th Order Store|k-th Order Stores|RDF Store|RDF Stores|Store|Stores"
							>k-th Order RDF Store</dfn> is a special case of <a>k-th order data
							structure</a> defined by cases: </p>
					<ol>
						<li>A zeroth-order RDF Store is a zeroth-order <a>repository</a>. </li>
						<li>A first-order RDF Store is a first-order <a>repository</a>.</li>
						<li> A (k+2)-th order RDF Store, k = 0, 1, ..., is a (k+2)-th order data
							structure with the following properties. <ul>
								<li>It has a static part whose default part is a (k+1)-th order
									repository, called the default repository of the store, and
									whose named part consists of named (k+1)-th order repositories,
									called named repositories of the store. </li>
								<li>It has an optional dynamic part which is a non-empty <a>data
										sequence</a> whose elements are named (k+1)-th order
									datasets, called versions of the store. The ordered set SV of
									the names of these versions are the <dfn>version names of the
										store</dfn>.</li>
								<li>The static and dynamic parts of a store St satisfy the following
									consistency requirements.</li>
								<ul>
									<li>For every repository name n in names(staticPart(St)), there
										is a monotonic partial mapping M<sub>n</sub> from SV onto
											<a>versionNames</a>( content(n, staticPart(St))); that
										is, from version names of the store to version names of the
										named repository of the store with name n. </li>
									<li>The domain of M<sub>n</sub>, dom(M<sub>n</sub>), is an
										interval in SV.</li>
									<li>If stver is in dom(M<sub>repname</sub>), let repver =
											M<sub>repname</sub>(stver). Then <br /> content(repname;
											<a>versionContent</a>(stver; St)) =
											<a>versionContent</a>(repver; content(repname;
										staticPart(St))) </li>
									<li>There is a monotonic mapping M<sub>default</sub> of SV onto
										version names of the default repository.</li>
									<li>If stver in SV, let repver = M<sub>default</sub>(stver).
										Then <br /> default(<a>versionContent</a>(stver; St)) =
											<a>versionContent</a>(repver; default(Static(St))) </li>
								</ul>
							</ul>
						</li>
					</ol>
					<p>We define a constructor <dfn data-lt="constructor Store"
							>Store<sub>k</sub></dfn> for <a>k-th order stores</a>, k = 2, 3, ...,
						with the following arguments.</p>
					<ol>
						<li>The default (k-1)-th order repository of the store.</li>
						<li>The set of repository names.</li>
						<li>The mapping from repository names to (k-1)-th order repositories.</li>
						<li>The set of store version names.</li>
						<li>For each repository name, a monotonic partial function from an interval
							of store version names onto the names of versions of the associated
							repository.</li>
						<li>The monotonic mapping from store version names onto version names of the
							default repository.</li>
					</ol>
					<p>In addition to constructing a store in its entirety with
							<a>Store<sub>k</sub></a>, we define a basic operation
							<dfn>Append2Store</dfn> which creates a store by adding a version to it.
							<a>Append2Store</a> does not change the static part of a store, and it
						specifies the new store version through new versions of its
						repositories.</p>
					<p>The arguments of <a>Append2Store</a><sub>k</sub> are</p>
					<ol>
						<li>The input store to be modified </li>
						<li>The new store version name, which must be distinct from previous store
							version names.</li>
						<li>A mapping M<sub>default</sub> from zero or one name (the new version
							name of the default repository) to a dataset of order (k-2) or
							less.</li>
						<li>A mapping M<sub>named</sub> from zero or more repository names to
							mappings from zero or one new version names to datasets of order (k-2)
							or less. The repository names may be repository names of the input store
							or may be new repository names. </li>
						<li>A mapping M<sub>new</sub> from zero or more repository names to
							repositories of order (k-1) or less having exactly one version. The
							repository names MUST be new for the store. </li>
						<li>A set S<sub>drop</sub> of zero or more repository names that are being
							dropped. This set MUST be disjoint from the repository names in the
							previous two items, and can only include repository names of the input
							store.</li>
					</ol>
					<p>An <a>Append2Store</a> operation cannot be vacuous; it must append to at
						least one repository (default or named) or add at least one new named
						repository or drop at least one named repository. </p>
					<p>The semantics of <a>Append2Store</a> are defined in terms of the
								<a>Store<sub>k</sub></a> constructor and the
							<a>Append2Repository</a> basic operations, according to the following
						cases.</p>
					<ol>
						<li>If the default repository mapping M<sub>default</sub> is not empty, then
							let R<sub>default, new</sub> = Append2Repository(R<sub>default</sub>,
								M<sub>default</sub>); otherwise R<sub>default, new</sub> =
								R<sub>default</sub></li>
						<li>@@@</li>

					</ol>
					<!--
					<p>Given the sequence of store versions (i.e. the dynamic part of the store) and
						the mappings from store version names to repository version names, we can
						reconstruct the dynamic parts of the repositories. To describe this
						construction explicitly, we need a few additional basic operations.</p>
					<p>Let <dfn>Distinct</dfn> be a basic operation on sequences that collapses
						adjacent identical elements into a single element, producing a new
						sequence.</p>
					<p> Let <dfn>Map</dfn> be a basic operation on sequences that applies a unary
						function to every element of the sequence, producing a new sequence.</p>
					<p>We define the basic operation <dfn>Restrict</dfn> whose signature is a first
						argument of a <a>data sequence</a> of <a>named datasets</a> of k-th order or
						less, for some fixed k, and second argument a name or set of names, and
						output is a <a>data sequence</a> of datasets of (k-1)-th order or less.</p>
					<p> Let DSQ = [ [n<sub>i</sub>, DSQ<sub>i</sub>, k+1]]<sub>i in <i>I</i></sub>.
						Let I<sub>m</sub> = {i|i in I such that m is in names(DSQ<sub>i</sub>)}.
						Further let I<sub>M</sub> = Union<sub>m in M</sub> I<sub>m</sub>. Then </p>
					<p> Restrict(DSQ, name) = Distinct( [content(name, DSQ<sub>i</sub>)]<sub>i in
									<i>I<sub>name</sub></i></sub> ) </p>
					<p> = Distinct( Map( DSQ, (λx.content(name, content(x)) ) )</p>
					<p> Restrict(DSQ, names) = Distinct( [ Dataset-UNION({content(name,
							DSQ<sub>i</sub>)|name in names}) ]<sub>i in
							<i>I<sub>names</sub></i></sub> ) </p>
					<p> = Distinct( Map( DSQ, (λx.Dataset-UNION({content(name, content(x)|name in
						names})) ) )</p>
					<p>Similarly, we define <dfn>Restrict-DEFAULT</dfn> on a sequence of <a>named
							static data structures</a> of k-th order, for some fixed k, as
						follows.</p>
					<p> Restrict-DEFAULT(DSQ) = Distinct( [default( DSQ<sub>i</sub>)]<sub>i in
								<i>I</i></sub> ) </p>
					<p> = Distinct( Map( DSQ, (λx.default(content(x)) ) )</p>
					<p class="ednote">Is there a need for a combination union of default and
						named?</p>
					<p>Using the store history, we can form the "union" of histories of repositories
						that are in the store (as named and/or default), because the relative order
						of revisions of these repositories has been recorded in the history of the
						store.</p>
					<p> Let R<sub>i</sub> = content(name<sub>i</sub>, staticPart(S)), and
							R<sub>j</sub> = content(name<sub>j</sub>, staticPart(S)), for some
							name<sub>i</sub> and name<sub>j</sub> in names(S). Then the <dfn>dynamic
							union</dfn> of named repositories [name<sub>i</sub>, R<sub>i</sub>, k]
						and [name<sub>i</sub>, R<sub>i</sub>, k] in the context of store S is:</p>
					<p> Dynamic-UNION(S, {name<sub>i</sub>, name<sub>j</sub>}) = Restrict(
						dynamicPart( S ), {name<sub>i</sub>, name<sub>j</sub>} ) </p>
						-->
					<p class="ednote">The intended semantics, under any entailment regime, of a
						k+1-th Order <a>RDF Store</a> is derived from that of the corresponding
						k+1-th Order RDF Repository (the dynamic part of the store), supplemented by
						that of its member k-th Order Repositories, possibly augmented (e.g. in the
						provenance regime) by entailments that link the two. </p>
				</section>
				<section id="def-store-transformations">
					<h4>Store Transformations</h4>
					<section id="def-general-transformation">
						<h5>General Store Transformation</h5>
						<p>For store ST, we denote the ordered set of store version names as
								<a>versionNames</a>(ST).</p>
						<p class="note">The function <a>versionNames</a> is defined above for
							repositories. The notation <a>versionNames</a>(ST) is an extensions of
							this function such that <a>versionNames</a>(ST) =
								<a>versionNames</a>(<a>dynamicPart</a>(ST))</p>
						<p>To streamline the definition of store transformations, we define two
							reserved names, denoted as <dfn>DEFAULT</dfn> and <dfn>STATIC</dfn> that
							will be used as the names, resp., of the default structure within
								<a>static data structures</a> and of the static structure within
							general <a>data structures</a></p>
						<p>For a set s of names, let <dfn>Ext-STATIC</dfn>(S) = S ∪ {STATIC}, and
								<dfn>Ext-DEFAULT</dfn>(S) = S ∪ {DEFAULT}.</p>
						<p>For store ST, let <dfn>namePairs</dfn>(ST) be a subset of
								<a>Ext-STATIC</a>(<a>versionNames</a>(ST)) x
								<a>Ext-DEFAULT</a>(<a>names</a>(<a>staticPart</a>(ST))) such that
							[stver, repo] is in NP provided stver is a member of
								<a>Ext-STATIC</a>(<a>versionNames</a>(ST)) and repo is in
								<a>names</a>(<a>versionContent</a>(stver; ST).</p>
						<p>We define a basic operation <dfn>StoreTransformation</dfn><sub>k</sub>
							with domain and range being <a>stores</a> of order k or less. The input
							arguments of <a>StoreTransformation</a><sub>k</sub> are as follows. </p>
						<ol>
							<li>The input store ST of order k or less. Let SV =
								<a>versionNames</a>(ST), SV<sub>ext</sub>= <a>Ext-STATIC</a>(SV), RP
								= names(static(ST)), and RP<sub>ext</sub> = Ext-DEFAULT(RP). Let NP
								= <a>namePairs</a>(ST), and RV(n) = <a>versionNames</a>(content(n,
								ST)). <br /> Note: SV is the set of store version names of the input
								store, while RP is the set of repository names of the input store.
								NP is the set of pairs of names - the first name being a store
								version name and the second name being the name of a repositry
								present in that store version. RV(n) is the ordered set of version
								names of the repository with name n.</li>
							<li>An ordered set SV', possibly empty, of version names of the output
								store. Let SV'<sub>ext</sub> = <a>Ext-STATIC</a>(SV').</li>
							<li>A set RP', possibly empty, of repository names of the output store.
								Let RP'<sub>ext</sub> = Ext-DEFAULT(RP')</li>
							<li>For each name n in RP'<sub>ext</sub>, an ordered set RV'(n),
								possibly empty, of version names of the corresponding output named
								or default repository. Let RV'(n)<sub>ext</sub> =
								Ext-STATIC(RV'(n)).</li>
							<li>A monotonic partial mapping M'<sub>n</sub>, for each name n in
									RP'<sub>ext</sub> from an interval of SV' onto RV'(n). Let NP' =
								{[m, n] | n in RP'<sub>ext</sub>, m in dom(M'<sub>n</sub>) }, the
								set of <a>namePairs</a> of the output store.</li>
							<li>A relation Rel<sub>data</sub> on NP x NP'. This relation describes
								the subsampling, duplication, and rearrangment of datasets from the
								input store to the output store, possibly including dataset
								unions.</li>
						</ol>
						<p>There are certain additional constraints on the arguments or output of
								<a>StoreTransformation</a>, as follows.</p>
						<ul>
							<li>M'<sub>DEFAULT</sub> is a total mapping on SV'.</li>
							<li>Repository revisions cannot be vacuous. If the evaluation generates
								"repositories" with vacuous revisions, these are deleted from the
								output in order to have a valid output store.</li>
							<li>Store revisions cannot be vacuous. If the evaluation generates a
								"store" with vacuous revisions, these are deleted from the output in
								order to have a valid output store.</li>
						</ul>
						<p>The semantics of <a>StoreTransformation</a><sub>k</sub> is defined as
							follows. For (input) store (ST, SV', RP', RV', M', Rel<sub>data</sub>),
							let</p>
						<ul>
							<li>DS<sub>m, n</sub> = content(n, versionContent(m, ST)) for each [m,
								n] in NP. </li>
							<li> DS'<sub>p', n'</sub> = Dataset-UNION({DS<sub>m, n</sub> | [ [m, n],
								[m', n']] in Rel<sub>data</sub>, M'<sub>n'</sub>(m') = p'})</li>
							<li>R'<sub>n'</sub> = <a>Repository</a><sub>k-1</sub>( DS'<sub>STATIC,
									n'</sub>, RV'(n'), { p' => DS'<sub>p',n'</sub> | p' in RV'(n') }
								), for n' in RP'<sub>ext</sub></li>
							<li>M'' is the mapping M' composed with the version name substitution
								arising from the reconciliation of vacuous revisions in the
								construction of repositories R'.</li>
						</ul>
						<p>Then the value of <a>StoreTransformation</a><sub>k</sub>(ST, SV', RP',
							RV', M', Rel<sub>data</sub>) is equal to the value of the constructor
								<a>Store</a><sub>k</sub> with the following arguments.</p>
						<ol>
							<li>the default repository R'<sub>DEFAULT</sub> of the output store</li>
							<li>RP'</li>
							<li>{n' => R'<sub>n'</sub> | n' in RP'}</li>
							<li>SV'</li>
							<li>{n' => M''(n') | n' in RP'}</li>
							<li>M''(DEFAULT)</li>
						</ol>
						<p class="ednote">All constructors need to be fixed to use mappings over
							extended sets of names, e.g. extended with DEFAULT or STATIC, as
							appropriate. Store<sub>k</sub>(RP, R, SV, M)</p>
						<aside class="example" title="Identity Transformation">
							<p>The output store is equal to the input store when the following
								hold.</p>
							<ul>
								<li>RP' = RP</li>
								<li>SV' = SV</li>
								<li>RV'(n) = RV(n) for every n in RP<sub>ext</sub></li>
								<li>Rel<sub>data</sub> is the identity relation on NP x NP, denoted
										<i>IDR</i><sub>NP</sub>
								</li>
								<li>M'<sub>n</sub> = M<sub>n</sub>, for each name n in
										RP'<sub>ext</sub>, where M<sub>n</sub> is the corresponding
									mapping in the input store.</li>
							</ul>
							<p>That is,</p>
							<p>ST = StoreTransformation<sub>k</sub>(ST, RP, SV, RV,
								IDR<sub>NP</sub>, M ) where k = order(ST), RP = names(static(ST)),
								SV = versionNames(ST), RV = { n => RV<sub>n</sub> | n is in RP and
									RV<sub>n</sub> = versionNames( content(n, static(ST) ) }, NP =
								namePairs(ST), M = versionNameMap(ST).</p>
						</aside>
						<aside class="example" title="Subsampling a Store">
							<p>The output store is equal to the input store except for subsampling
								of the versions in one or more repositories when the following
								hold.</p>
							<ul>
								<li>RP' = RP</li>
								<li>SV' = SV</li>
								<li>RV'(n) is a subset of RV(n) for every n in RP<sub>ext</sub></li>
								<li>M'<sub>n</sub>(m') = max( { p | m &le; m' and p =
									M<sub>n</sub>(m) is in RV'(n) } ).</li>
								<li> Rel<sub>data</sub> = {[[m', n], [m, n]] | [m, n] is in NP and
										M'<sub>n</sub>(m') = M<sub>n</sub>(m) } </li>
							</ul>
							<li>Let <dfn>Subsample</dfn>(ST, RV') =
									<a>StoreTransformation</a><sub>k</sub>(ST, RP, SV, RV',
									Rel<sub>data</sub>, M') with Rel<sub>data</sub> and M' as
								defined above.</li>
						</aside>
						<aside class="example" title="Dynamic Union of Two Repositories">
							<p>The output store is equal to the input store except for the dynamic
								union of two named repositories into a new named repository when the
								following hold.</p>
							<ul>
								<li>RP' = (RP ∪ {r'}) - {r1, r2} where r1, r2 are the names of the
									repositories that are unioned, and r' is the (new) name of the
									result of the union.</li>
								<li>SV' = SV</li>
								<li>RV'(n) = RV(n) for every n in RP<sub>ext</sub> - {r1, r2}</li>
								<li>if n is in RP - {r1, r2}, then [[m, n], [m', n']] belongs to
										Rel<sub>data</sub> iff m' = m and n' = n.</li>
								<li>if n is in {r1, r2}, then [[m, n], [m', n']] belongs to
										Rel<sub>data</sub> iff n' = r', [m, n] is in NP, and m' = m
									. </li>
								<li>M'<sub>n</sub> = M<sub>n</sub>, for each name n in
										RP'<sub>ext</sub> - {r1, r2}.</li>
							</ul>
							<p>Let <dfn>Dynamic-UNION</dfn>(ST, R, r', RV'(r')) =
									<a>StoreTransformation</a><sub>k</sub>(ST, RP', SV, RV',
									Rel<sub>data</sub>, M') with RP', RP', Rel<sub>data</sub> and M'
								as defined above. </p>
						</aside>
						<aside class="example" id="ex-rename" title="Renaming Operation">
							<p> A new store may be created using a name substitution Subst that maps
								all names that appear in the store to names. Since names may be used
								both in the structural aspects, e.g. version or repository names,
								and in the content, then both must be subject to the
								substitution.</p>
							<p>Subst may not substitute for or with the reserved names DEFAULT or
								STATIC.</p>
							<p>Substitutions into an ordered set preserve the order, e.g as if the
								order assertions were materialized and subject to substitution.</p>
							<p><dfn>Rename(ST, Subst)</dfn> = <a>Store<sub>k</sub></a>(Subst(RP),
								Subst(R), Subst(SV), Subst(M)) where Subst is a name substitution
								mapping.</p>
							<p>The name-substituted store will entail a substituted version of the
								entailments of the original store in simple and structural
								entailment regimes.</p>
						</aside>
						<aside class="example" id="ex-window" title="Count-Based Window Operation">
							<p> We define some auxiliary functions to assist with count-based window
								operations. </p>
							<p> Let <dfn>Comb<sub>p</sub></dfn>(A, a) select from a totally-ordered
								set A containing element a the elements of A that are offset, with
								respect to order, an integer multiple of p from element a. That is,
								elements b such that there are exactly k * (p) elements c with a
								&lt; c &le; b or b &lt; c &le; a. </p>
							<p>Let Interval<sub>n</sub>(A) be the ordered set of all intervals of
								length n in A, with order by minimal element, and
									Interval<sub>n</sub>(A, a) be the interval of length n in A
								whose minimal element is a.</p>
							<p>Let Floor<sub>n</sub>(A, a) = { m' => m | m' is in
									Interval<sub>n</sub>(A, m) and m is in Comb<sub>n</sub>(A, a)
								}</p>
							<!--
							<p>We define a basic operation <dfn>Window</dfn><sub>n, p</sub>(A, a) =
									Comb<sub>p</sub>( Interval<sub>n</sub>(A),
								Interval<sub>n</sub>(A, a) ) where n and p are positive integers,
								and A is a totally-ordered set, and a is an element in A.</p>
								-->
							<p>We define WindowRel<sub>q, p</sub>(V, v0) = { [v, v'] | if v' is in
									Comb<sub>p</sub>(V, v0) and v is in Interval<sub>q</sub>(V, v')
								} </p>
							<p>Let [[m, n], [m', n]] belong to WindowRel<sub>p, q</sub>(ST, N, v0)
								if [m, n] is in NP, n is in N = dom v0, v' is in RV'<sub>n</sub> =
									Comb<sub>q</sub>(RV<sub>n</sub>, v0<sub>n</sub>), v is in
									Interval<sub>p</sub>(RV<sub>n</sub>, v') where v =
								M<sub>n</sub>(m), v' = M<sub>n</sub>(m'). </p>
							<p>Let <dfn>Window</dfn>(ST, n, p, q, rv0) =
									<a>StoreTransformation</a><sub>k</sub>( ST, RV'<sub>n</sub>,
								{n}, {DEFAULT->{}, n=>RV'<sub>n</sub>}, {DEFAULT=>{}, n=>
									<i>IDM</i><sub>n</sub>}, WindowRel<sub>q, p</sub>(ST, {n}, {n =>
								rv0})) where</p>
							<ul>
								<li>RV'<sub>n</sub> = Comb<sub>q</sub>(RV<sub>n</sub>,
										v0<sub>n</sub>)</li>
								<li>RV<sub>n</sub> = <a>versionNames</a>(content(n, ST))</li>
								<li><i>IDM</i><sub>n</sub> is the identity mapping on
										RV'<sub>n</sub></li>
							</ul>
							<p class="ednote">If we use an expression rather than interval of fixed
								size, we can work towards semantic windowing based on a query of the
								structural metadata.</p>
						</aside>
						<aside class="example" title="Repository Extraction">
							<p>The <dfn>Repository-EXTRACT</dfn> operation takes a store ST and a
								set of repository names N, returning a substore that contains only
								repositories whose names are in N.</p>
							<p>Repository-EXTRACT<sub>k</sub>(ST, N) =
									<a>StoreTransformation</a><sub>k</sub>(ST, SV, RP', RV', M',
									Rel<sub>data</sub>) </p>
							<p>where</p>
							<ul>
								<li>RP' = RP &cap; N </li>
								<li>RV' is the restriction of RV to RP'</li>
								<li>M' is the restriction of M to RP'<sub>ext</sub></li>
							</ul>
						</aside>
					</section>
					<!--
					<section id="def-window-transformation">
						<h5>Window Functions on Stores</h5>
						<p>The RDF Stream document defines window operations on streams. We define
							here a basic operation, called <dfn>Restrict-FILTER</dfn> that performs
							a more general transformation on stores, which can be specialized to
							implement the window function on streams that are implemented through
								<a>stores</a>.</p>
						<p>The signature of <a>Restrict-FILTER</a> is like <a>Restrict</a>, except
							it has an extra argument which is a pattern. The value of the operation
							is a subsequence of the corresponding value of Restrict, but filtered to
							include only those elements where there is a non-empty result from
							applying the query to the contents of the associated version of the
							store. </p>
						<p>We next define a basic operation <dfn>Sequence-UNION</dfn> that operates
							on <a>data sequences</a> of datasets of k-th order or less. The result
							is the value of applyling <a>Dataset-UNION</a> to the set of all
							elements in the sequence. That is,</p>
						<p>Sequence-UNION([D<sub>i</sub>]<sub>i in <i>I</i></sub>) =
								Dataset-UNION({D<sub>i</sub>|i in <i>I</i>})</p>
						<p>Finally, we define a basic operation <dfn>Window</dfn> that takes as
							first argument a store, and second argument is a sequence of patterns.
							For each pattern in the sequence, the operation Restrict-FILTER is
							performed, and then Sequence-UNION is applied to the result, generating
							a sequence of datasets as the final result.</p>
						<p>That is,</p>
						<p><a>Window</a>(ST, [P<sub>i</sub>]<sub>i in <i>I</i></sub>)=
							[Sequence_UNION(Restrict_FILTER(ST, P<sub>i</sub>))]<sub>i in
								<i>I</i></sub></p>
					</section>
					-->
				</section>
				<section>
					<h4>Connection Between Repositories and Stores</h4>
					<p>Every <a>k-th order store</a> can be converted into a k-th order repository
						by keeping the dynamic part the same, and replacing the static part of the
						store with the default part of the static part of the store. This
						transformation loses information; in particular, it loses the names of
						repository versions. However, the contents and order of repository versions
						is not lost; this information is preserved in the dynamic part of the store,
						and can be recovered using the <a>Restrict</a> operation.</p>
					<p class="ednote">Restrict operator needs to be (re)-defined.</p>
					<p>Many <a>k-th order repositories</a> can be converted into a <a>k-th order
							store</a> by supplying (or minting) the additional version names
						necessary to generate (k-1)-th order repositories corresponding to the
						(k-1)-th order named datasets in the repository version contents. The
						primary requirement for this to be possible is that once a dataset name
						disappears from a repository version, it cannot reappear in a later
						version.</p>
				</section>
			</section>
			<section id="def-streams">
				<h3>Streams</h3>
				<p>RDF Streams are defined in the document @@@</p>
				<p>Here we define a datastructure and some operations that allow RDF Streams to be
					emulated as first or second-order data structures.</p>
				<section id="def-timestamped-graph">
					<h4>Timestamped Graphs as Second-Order Datasets</h4>
					<p>We define a constructor <dfn>TSGraph</dfn> for timestamped graphs with the
						following arguments.</p>
					<ol>
						<li>An RDF graph, the default graph of the timestamped graph with the
							exception of the timestamp triple.</li>
						<li>An RDF graph containing exactly one triple, that being the timestamp
							triple</li>
						<li>An optional RDF graph which is the content of the named graph of the
							timestamped graph.</li>
					</ol>
					<p>The value of <a>TSGraph</a> is defined in terms of other operations in the
						following cases.</p>
					<ul>
						<li>TSGraph(G0, {n p t.}) = Static<sub>1</sub>(G<sub>meta</sub>, {b}, {b =>
							D0}) </li>
						<li>TSGraph(G0, {n p t.}, G1) = Static<sub>2</sub>(G<sub>meta</sub>, {b}, {b
							=> D1}) </li>
						<li>where b is a fresh blank node and </li>
						<li>D0 = Dataset-UNION(G0, {n p t.})</li>
						<li>D1 = Static<sub>1</sub>(Dataset-UNION(G0, {n p t.}), {n}, {n => G1} ) </li>
						<li>G<sub>meta</sub> = { b rsp:usesTimestampPredicate p}</li>
						<li>with the requirement that G0 contain no triples using the predicate
							p.</li>
					</ul>
					<p>To get back the parts of a timestamped graph, we define the following basic
						operations as shortcuts for CONSTRUCT-form queries of the second-order
						dataset representing the timestamped graph under simple entailment.</p>
					<ul>
						<li><dfn>timestampTriple</dfn>(TSG) = {n p t.}</li>
						<li>other?</li>
					</ul>
				</section>
				<section id="def-rdf-stream-as-store">
					<h4>RDF Streams as Stores</h4>
					<p>We now show how to emulate an RDF stream as a <a>store</a>.</p>
					<section id="def-rdf-stream-as-second-order-store">
						<h4>RDF Streams as Second-Order Stores</h4>
						<p>In the case of an RDF stream where all elements are zeroth-order
							timestamped graphs (containing no named graph), we construct a stream as
							follows. </p>
						<p> Suppose the stream consists of the timestamped graphs in the sequence
								[TSG<sub>i</sub>] for i in an ordered set <i>I</i> where </p>
						<p>TSG<sub>i</sub> = TSGraph(G0<sub>i</sub>, {n<sub>i</sub> p<sub>i</sub>
								t<sub>i</sub>.}).</p>
						<p>Let S<sub>i</sub> be the stream emulation up to index i, using repository
							name rn. Then</p>
						<p>S<sub>i+1</sub> = <a>Append2Store</a><sub>2</sub>(ST, sv<sub>i+1</sub>,
								{sv<sub>i+1</sub> => G<sub>DEFAULT, i+1</sub>}, {rn =>
								{sv<sub>i+1</sub> => G0<sub>i+1</sub>}} &cup; {n<sub>i+1</sub>
								p<sub>i+1</sub> t<sub>i+1</sub>.}, {}, {} )</p>
						<p>where sv<sub>i+1</sub> is a fresh name for the store version and </p>
						<p>G<sub>DEFAULT, i+1</sub> = defaultPart(TSG<sub>i+1</sub>)</p>
					</section>
				</section>
			</section>
		</section>
		<section id="abstract-syntactic-categories">
			<h2>Abstract Syntactic Categories</h2>
			<p>In this section, we review the abstract syntactic categories defined in other
				recommendations and state the definitions of new abstract syntactic categories that
				support the signature definitions of new algebra operators.</p>
			<section id="existing-abstract-syntactic-categories">
				<h3>Existing Abstract Syntactic Categories</h3>
				<p class="ednote">For now, I keep this table here as a summary of definitions and
					links to the recommendations for existing datatypes. In the final document, this
					table will be moved to an appendix, or deleted. </p>
				<p>We make use of the following data structure types from other specifications in
					the RDF and SPARQL family:</p>
				<div style="text-align: left;">
					<table class="thinborder" style="margin-left: auto; margin-right: auto;">
						<caption id="existing-abstract-syntactic-categories-table"><b>Table C</b>:
							Existing abstract syntactic categories used in this specification,
							excluding data structures</caption>
						<tbody>
							<tr>
								<td><b>Syntactic Category</b></td>
								<td><b>Reference</b></td>
								<td><b>Definition</b>
								</td>
							</tr>
							<tr>
								<td><dfn data-lt="RDF Terms">RDF-T</dfn></td>
								<td>[[!SPARQL11-Query]] <a
										href="https://www.w3.org/TR/2013/REC-sparql11-query-20130321/#sparqlBasicTerms"
										>#sparqlBasicTerms</a></td>
								<td> Let <dfn>I</dfn> be the set of all <a>IRIs</a>. Let
										<dfn>RDF-L</dfn> be the set of all <a>RDF Literals</a> Let
										<dfn>RDF-B</dfn> be the set of all <a>blank nodes</a> in
										<a>RDF graphs</a>. The set of RDF Terms, RDF-T, is I ∪ RDF-L
									∪ RDF-B. </td>
							</tr>
							<tr>
								<td><dfn>V</dfn></td>
								<td>[[!SPARQL11-Query]] <a
										href="https://www.w3.org/TR/2013/REC-sparql11-query-20130321/#sparqlQueryVariables"
										>#sparqlQueryVariables</a></td>
								<td>A query variable is a member of the set V where V is infinite
									and disjoint from RDF-T. </td>
							</tr>
							<tr>
								<td><dfn>expression</dfn></td>
								<td><b>Reference</b></td>
								<td><b>Definition</b>
								</td>
							</tr>
							<tr>
								<td><dfn>Graph Pattern</dfn></td>
								<td><b>Reference</b></td>
								<td><b>Definition</b>
								</td>
							</tr>
							<tr>
								<td><dfn>Quadpattern</dfn> or <dfn>GraphGraphPattern</dfn></td>
								<td> [[!SPARQL11-Update]] [[!SPARQL11-Query]] <a
										href="https://www.w3.org/TR/2013/REC-sparql11-query-20130321/#sparqlTranslateGraphPatterns"
										>#sparqlTranslateGraphPatterns</a>
								</td>
								<td><b>Definition</b>
								</td>
							</tr>
							<tr>
								<td><dfn>Query</dfn></td>
								<td><b>Reference</b></td>
								<td><b>Definition</b>
								</td>
							</tr>
						</tbody>
					</table>
				</div>
			</section>
			<section id="patterns">
				<h3>Patterns</h3>
				<section id="kth-order-pattern">
					<h4>k-th Order Pattern</h4>
					<p>A <dfn data-lt="k-th Order patterns|pattern|patterns">k-th Order
							pattern</dfn> is @@@ </p>
				</section>
			</section>
		</section>
		<section id="abstract-algebra">
			<h2>Abstract Algebra Operations</h2>
			<section id="def-existing-query">
				<h3>SPARQL Query Abstract Algebra</h3>
				<section id="def-existing-query-eval">
					<h4>Eval</h4>
					<p>We define an extension of the signature, and the corresponding semantics, of
						the "eval" operation of [[!SPARQL11-Query]] that accommodates two
						styles:</p>
					<ul>
						<li>A syntactic style that uses reserved words to modify data structures,
							e.g. by casting to different types, extracting substructures or applying
							window operations.</li>
						<li>A semantic style that uses naming conventions within the IRI, e.g. with
							query strings, to indicate such modifications of the data
							structures.</li>
					</ul>
					<p> In either case, it is necessary that the transformation to the abstract
						algebra does not depend on any details of the IRI; i.e., IRIs are still
						opaque. </p>
					<p>However, it is acceptable, even typical, that the <em>semantics</em> of the
						abstract operations depend on the datatype of the arguments. </p>
					<p> Thus, we extend the binary signature of the eval function from its
						definition in [[!SPARQL11-Query]] of RDF Dataset x expression, to take a
						data structure of the various types defined in Section <a
							href="#data-structures"></a>, as first argument and an extended pattern,
						as defined in Section <a href="#patterns"></a> as second argument. </p>
					<p>All of the newly-defined data structures can be considered as specializations
						of an abstract data structure having an (optional) static part and an
						(optional) dynamic part. This same abstraction holds for:</p>
					<ul>
						<li>data strucutures with triples as the fundamental type (datasets,
							repositories, stores, streams)</li>
						<li>data structures with solution mappings as the fundamental type
							(structured results)</li>
					</ul>
					<p> The semantics of eval are based on matching the pattern to the dynamic part
						of the data structure, with the static part unioned into every element, to
						obtain the dynamic part of the structured result, and also matching the same
						pattern to the static part of the data structure to get the static part of
						the structured result. </p>
					<p>In the semantic approach, the implementer defines the naming convention of
						the query string to denote substructures of the parent data structure, e.g
						just the static part, just the dynamic part, just the terminal element of
						the dynamic part, or structures derived from the parent structure, e.g. the
						dynamic part with the static part unioned into every element, or the result
						of a window operation, where subsequences from the dynamic part are unioned
						to obtain a new sequence. </p>
					<p>In the syntactic approach, abstract algebra operations are employed to
						express these transformations and associate them with variables or names,
						with a syntactic transformation to and from the concrete syntax.
						<!--The motivation for the syntactic approach is to allow the same capability for transformation as the semantic approach in regard to external and legacy sources.-->
					</p>
				</section>
			</section>
			<section id="def-existing-basic">
				<h3>Basic Operations</h3>
				<section id="def-existing-basic-dataset-union">
					<h4>Dataset-UNION</h4>
					<p><dfn>Dataset-UNION</dfn> is defined in [[!SPARQL11-Update]] as a basic
						operation with the following signature:</p>
					<ul>
						<li>On the domain RDF Dataset x RDF Dataset, the range is RDF Dataset.</li>
					</ul>
					<p>The semantics of <a>Dataset-UNION</a> is defined in [[!SPARQL11-Update]] as
						follows.</p>
					<p> Let DS={DG} union {(iri<sub>i</sub>, G<sub>i</sub>) | 1 ≤ i ≤ n} and DS' =
						{DG'} union {(iri'<sub>j</sub>, G'<sub>j</sub>) | 1 ≤ j ≤ m} be two RDF
						Datasets. Let further graphNames(DS) = { iri<sub>i</sub> | 1 ≤ i ≤ n} and
						graphNames(DS') = {iri'<sub>j</sub> | 1 ≤ j ≤ m}. The Dataset-UNION between
						DS and DS' is defined as follows: </p>
					<p>Dataset-UNION(DS, DS') = {DG union DG'} union {(iri, G) | iri in
						graphNames(DS) union graphNames(DS')}</p>
					<p>and G defined as </p>
					<ul>
						<li>G<sub>i</sub> for iri = iri<sub>i</sub> such that iri<sub>i</sub> in
							graphNames(DS) minus graphNames(DS')</li>
						<li>G<sub>j</sub> for iri = iri'<sub>j</sub> such that iri<sub>j</sub> in
							graphNames(DS') minus graphNames(DS)</li>
						<li>G<sub>i</sub> union G<sub>j</sub> for iri = iri<sub>i</sub> =
								iri'<sub>j</sub> in graphNames(DS) intersect graphNames(DS')</li>
					</ul>
					<p>where union between <a>graphs</a> is defined as set-union of <a>triples</a>
						in those <a>graphs</a>.</p>
					<p>The Dataset-UNION operation constructs a new <a>RDF 1.1 Dataset</a> from two
						existing <a>RDF 1.1 Datasets</a> by forming the union of the <a>default
							graphs</a>, and taking the union of the sets of <a>named graphs</a>,
						with the exception that if the sets of graph names of the two <a>RDF 1.1
							datasets</a> have a non-empty intersection, the <a>graphs</a> with names
						in that intersection must be combined by set union. </p>
					<p> We extend the Dataset-UNION operation to <a>k-th Order RDF Datasets</a>.
						Also, the names are extended from IRIs to also allow <a>blank node</a>
						names. </p>
					<ul>
						<li>On the domain <a>k-th order dataset</a> x k'-th order <a>dataset</a>,
							the range is max(k, k')-th order <a>dataset</a>.</li>
						<li>On the domain of sets of <a>datasets</a> of order k or less, the range
							is <a>k-th order datasets</a>.</li>
					</ul>
					<p>The extended semantics of <a>Dataset-UNION</a> is defined by cases as
						follows.</p>
					<p>In the case of two arguments DSP, DSP':</p>
					<ul>
						<li>If DSP and DSP' are both zeroth-order <a>datasets</a>, i.e., <a>RDF
								Graphs</a>, then the result is the union of the sets of
								<a>triples</a> in the two <a>graphs</a>. </li>
						<li>If order(DSP) = order(DSP') = k &gt; 0, then <br /> Dataset-UNION(DSP,
							DSP') = Static<sub>k</sub>( Dataset-UNION(default(DSP), default(DSP')),
							names(DSP) ∪ names(DSP'), result-nameMap ) <br /> where result-nameMap =
							<br /> { name = > content(name, DSP) | name in names(DSP) - names(DSP')}
							∪ <br /> { name = > content(name, DSP') | name in names(DSP') -
							names(DSP)} ∪ <br /> { name = > Dataset-UNION( content(name, DSP),
							content(name, DSP')) | name in names(DSP) &amp; names(DSP')} </li>
						<li>If order(DSP') &lt; order(DSP) = k, then <br /> Dataset-UNION(DSP, DSP')
							= Dataset-UNION(DSP', DSP) = Static<sub>k</sub>(
							Dataset-UNION(default(DSP), DSP'), names(DSP) , result-nameMap ) <br />
							where result-nameMap = { name = > content(name, DSP) | name in
							names(DSP)} </li>
					</ul>
					<p>In the case of a single argument S that is a set of <a>datasets</a> of order
						k or less, the value is defined inductively as follows.</p>
					<ul>
						<li>if S = {}, then Dataset-UNION(S) = {}.</li>
						<li>if order(s) = 0 for every s in S (i.e. s is an <a>RDF graph</a>), then
							Dataset-UNION(S) = ∪<sub>s in S</sub>s.</li>
						<li>if order(s) = k &gt; 0 for every s in S, then <br /> Dataset-UNION(S) =
								Static<sub>k</sub>( result-default, result-names, result-nameMap )
							<br /> where <br /> result-default = Dataset-UNION({default(s)|s in S})
							<br /> result-names = ∪<sub>s in S</sub> names(s), <br /> result-nameMap
							= { n => Dataset-UNION({content(n, s)|<sub>s in S</sub>}) | n in
							result-names} </li>
						<li> if max({order(s)|s in S}) = k &gt; 0, let S<sub>k</sub> be the subset
							of S containing all members of S having order k. Then Dataset-Union(S) =
							Dataset-UNION( Dataset-UNION(S -S<sub>k</sub>),
								Dataset-UNION(S<sub>k</sub>)) </li>
					</ul>
					<p class="ednote"> It is possible to informally apply the Dataset-UNION
						operation to pairs of <a>repositories</a> or <a>stores</a> by first applying
						a forgetful functor that retains all the versions but forgets the order
						among them. However, the result is not a <a>repository</a> or <a>store</a>,
						but is just a <a>dataset</a>. To truly extend the UNION operation to
							<a>repositories</a> and <a>stores</a> to generate new
							<a>repositories</a> and <a>stores</a>, it would be necessary to mint new
						version names and to specify how versions are ordered and combined when
						necessary e.g. according to timestamps, but timestamps are not mandatory in
						our definitions There is no precedent for such definitions, since the Update
						spec does not define a union operation on Graph Stores. </p>
					<p class="ednote">We do define a special case of "union" for <a>repositories</a>
						that are all members of the same <a>store</a> using the <a>Dynamic-UNION</a>
						operation.</p>
				</section>
				<section>
					<h4>Other Basic Operations</h4>
					<p class="ednote">Similarly, the basic operations of Dataset-DIFF and Dataset
						will be extended to <a>k-th order datasets</a>. The Dataset operation will
						also be extended to <a>k-th order patterns</a>. </p>
				</section>
			</section>
			<section id="def-existing-update">
				<h3>SPARQL Update Operations</h3>
				<section id="def-existing-update-insert-data">
					<h4>Insert Data</h4>
					<p><dfn>Insert Data</dfn> is defined in [[!SPARQL11-Update]] as an Update
						Operation with the following signature:</p>
					<ul>
						<li>On the domain RDF Dataset x IRI, the range is RDF Dataset.</li>
					</ul>
					<p>The semantics of <a>Insert Data</a> is defined in [[!SPARQL11-Update]] as
						follows.</p>
					<p>OpInsertData(GS, <em>QuadPattern</em>) = Dataset-UNION(GS,
							Dataset(<em>QuadPattern</em>,{},GS,GS))</p>
					<p>where {} is the empty solution mapping,</p>
					<p> GS is an <a>RDF 1.1 dataset</a>, and <em>QuadPattern</em> is a ground quad
						pattern. </p>
					<p>The Insert Data operation constructs a new RDF Dataset from an existing RDF
						Dataset by adding triples and quads to it as expressed in the ground
							<em>QuadPattern</em>. Note that Insert Data is functional in that it
						does not actually "change" the input RDF Dataset. Update operations may be
						used to define a Graph Store as a state machine, where the state of a Graph
						Store is an RDF Dataset, and Update Operations take the current state of a
						Graph Store as one of their input arguments, generating a new RDF Dataset
						which then is taken as the new state of the Graph Store. </p>
					<p> We extend the Insert Data operation to <a>k-th Order RDF Datasets</a>. </p>
					<ul>
						<li>On the domain <a>k-th Order RDF Datasets</a> x Ground <a>k-th Order
								Patterns</a>, the range is <a>k-th Order RDF Datasets</a>.</li>
					</ul>
					<p>The extended semantics of <a>Insert Data</a> is defined as follows.</p>
					<p><dfn>OpInsertData</dfn>(DS, <em>k-Pattern</em>) = Dataset-UNION(DS,
							Dataset(<em>k-Pattern</em>,{},DS,DS))</p>
					<p>where {} is the empty solution mapping,</p>
				</section>
				<section id="def-existing-update-opcreate">
					<h4>OpCreate</h4>
					<p><dfn>OpCreate</dfn> is defined in [[!SPARQL11-Update]] as an Update Operation
						with the following signature:</p>
					<ul>
						<li>On the domain RDF Dataset x IRI, the range is RDF Dataset.</li>
					</ul>
					<p>The semantics of <a>OpCreate</a> is defined in [[!SPARQL11-Update]] as
						follows.</p>
					<p>Let GS = {DG} union {(iri<sub>i</sub>, G<sub>i</sub>) | 1 ≤ i ≤ n} and
						graphNames(GS) = { iri<sub>i</sub> | 1 ≤ i ≤ n}, then</p>
					<p>OpCreate(GS, iri) = GS union {(iri, {})} if iri not in graphNames(GS);
						otherwise, OpCreate(GS, iri) = GS</p>
					<p> where DG and G<sub>i</sub> are graphs, iri and iri<sub>i</sub> are IRIs. </p>
					<p>The OpCreate operation constructs a new RDF Dataset from an existing RDF
						Dataset by adding an empty named graph to it with a specified IRI as name,
						provided it does not already contain a named graph of the specified name.
						Note that OpCreate is functional in that it does not actually "change" the
						input RDF Dataset. Update operations may be used to define a Graph Store as
						a state machine, where the state of a Graph Store is an RDF Dataset, and
						Update Operations take the current state of a Graph Store as input,
						generating a new RDF Dataset which then is taken as the new state of the
						Graph Store. </p>
					<p> We extend the OpCreate operation to <a>k-th Order RDF Datasets</a>. Also,
						the names are extended from IRIs to also allow blank node names. </p>
					<ul>
						<li>On the domain <a>k-th Order RDF Dataset</a> x I ∪ RDF-B, the range is
							max(k, 1)-th Order <a>datasets</a>.</li>
						<li>On the domain <a>k-th Order RDF Dataset</a> x I ∪ RDF-B x Int, the range
							is <a>datasets</a></li>
					</ul>
					<p>The extended semantics of <a>OpCreate</a> is defined as follows.</p>
					<ul>
						<li>OpCreate(DS, name) = OpCreate(DS, name, max(order(DS), 1)).</li>
						<li>If name is in name(DS), and k = order(DS), then OpCreate(DS, name, k) =
							DS.</li>
						<li>If k &gt; order(DS), then OpCreate(DS, name, k) = Static<sub>k</sub>(DS,
							{name}, {name => {}})</li>
						<li>If k = order(DS) and name is not in name(DS), then OpCreate(DS, name, k)
							= Static<sub>k</sub>(default(DS), names(DS) ∪ {name}, nameMap(DS) ∪
							{name => {}}). </li>
						<li>If k &lt; order(DS) = k', then OpCreate(DS, name, k) =
								Static<sub>k'</sub>( OpCreate(default(DS), name, k), names(DS),
							nameMap(DS) ) )</li>
					</ul>
				</section>
				<section>
					<h4>Other Update Operations</h4>
					<p class="ednote">Similarly, the Update Operations of SPARQL Update can be
						extended to <a>k-th order datasets</a>, making use of the extended basic
						operations. </p>
				</section>
			</section>
			<section id="def-new-apply-operation">
				<h4>Apply Operation</h4>
				<p class="ednote">The above extensions only allow management, e.g. creation of a new
					"slot", at the top level of a <a>k-th order dataset</a>. However, it is also
					useful to be able to apply operations at a deeper level within a <a>k-th order
						dataset</a>. This capability can be enabled with a generic operation, called
						<dfn>Apply</dfn>, which takes a <a>k-th order dataset</a> as first argument,
					an Operation specification (unary function built from Operation name and tuple
					of arguments with a placehoder in one position) as second argument, and an
					optional third argument that is an IRI or blank node. The result would be the
					result of applying that Operation with the appropriate (named or default)
					(k-1)-th order dataset replacing the placeholder, and then substituting for the
					(k-1)-th order dataset with the operation result within the original <a>k-th
						order dataset</a>. If the name is not in the set of database names, then the
					result would be the original dataset. </p>
				<ul>
					<li>If name is in names(DS), then APPLY(DS, Spec, name) =
							Static<sub>order(DS)</sub>( default(DS), names(DS), Delete(nameMap(DS),
						name) union { name => Spec(content(name, DS))} ) </li>
					<li>Otherwise, APPLY(DS, Spec, name) = DS.</li>
					<li>APPLY(DS, Spec) = Static<sub>order(DS)</sub>( Spec(default(DS)), names(DS),
						nameMap(DS) )</li>
				</ul>
			</section>
			<section id="def-new-revise-operation">
				<h4>Revise Operation</h4>
				<p>Update Operations as defined in SPARQL Update, and here extended, are not
					directly applicable to <a>repositories</a> and <a>stores</a>. In order to enable
					them, we define a Revise operation, that takes as input a <a>repository</a>
					(with a terminal version) as first argument, an Update Operation specification
					as second argument and a name (IRI or blank node) as third argument. The result
					is a new <a>repository</a> that has an additional <a>version</a>, that being the
					result of applying the Update Operation to the terminal <a>version</a> of the
					input repository, and making that the new terminal version, using the specified
					name as the version name. </p>
				<p>The Revise Operation may be extended to <a>stores</a> in the obvious fashion.
					However, this only allows manipulation of the version sequence of the store. To
					enable direct manipulation of the version sequence of repositories within the
					store, we extend the <a>Apply</a> Operation, defined above for <a>k-th order
						datasets</a> and Update Operation specifications, to <a>stores</a> and
					Revise Operation specifications on repositories (only for unnested Revise). </p>
				<p>Application of a Revise operation to a structure without a terminal version is an
					error. </p>
			</section>
			<!--
		  <section>
		  <p class="ednote">Options for extending Update Operations to the Store/Repository model are:
		  </p>
		  <ol>
		    <li>Follow the functional approach by defining functions that act on the "state" of a Store, 
			(defined in terms of the Repositories, named or default, that it owns), 
			producing a new state.
			This state then presumably becomes the current state of the mutable Store, just like in the SPARQL UPDATE spec,
			but the mutability of a Store is not addressed explicitly.
			However, the mutability of Repositories is explicitly addressed, 
			these being the objects that make up the state of a Store.
			</li>
			<li>Handle the mutability of Stores explicitly by defining mutator methods on Store "objects".
			</li>
			<li>Take a full-blown functional approach by hiding all mutability.
			The "state" of a Store is then not expressed in terms of Repositories, but in terms of the "states"
			of its Repositories.
			The state of a Repository is an RDF Dataset, in parallel to the state of a Graph Store being an RDF graph.
			</li>
		  </ol>
		  
		  <p>Here is what the first option would look like:
          </p>
		  <p>
		  We further extend the OpCreate operation to <a>k-th Order Stores</a>.
		  </p>
		  <ul>
		    <li>On the domain <a>k-th Order Store</a> x I ∪ RDF-B, the range is <a>k-th Order Store</a>.</li>
		  </ul>
		  <p>The extended semantics of <a>OpCreate</a> is defined as follows.</p> 
		  <p>Let S<sup>k</sup> = {R<sup>k</sup>} ∪ 
		  {(name<sub>i</sub>, R<sup>k</sup><sub>i</sub>) | 1 ≤ i ≤ n} and 
		  datasetNames(R<sup>k</sup>) = { name<sub>i</sub> | 1 ≤ i ≤ n}, then</p>
		  <p>OpCreate(S<sup>k</sup>, name) = S<sup>k</sup> ∪ {(name, R<sup>k</sup><sub>0</sub>)} 
		  if name not in datasetNames(S<sup>k</sup>); 
		  otherwise, OpCreate(S<sup>k</sup>, name) = S<sup>k</sup></p>
		  <p>
		  where S<sup>k</sup> is a <a>k-th Order Store</a>, 
		  R<sup>k</sup><sub>i</sub> are <a>k-th Order Repositories</a>, 
		  name and name<sub>i</sub> are IRIs or blank nodes (I ∪ RDF-B)
		  and  R<sup>k</sup><sub>0</sub> is the empty <a>k-th Order Repository</a>.
		  </p>
		  -->
			<!--
		  <p>We extend the syntax of OpCreate to include the following additional signature:</p>
		  <ul>
		    <li>On the domain StoreState x IRI, the range is StoreState.</li>
		  </ul>
		  <p>The semantics of <a>OpCreate</a> on the domain extension is defined as follows.</p> 
		  <p>Let SS = {DR} union {NR<sub>i</sub> | 1 ≤ i ≤ n} and repositoryNames(SS) = { name(NR<sub>i</sub>) | 1 ≤ i ≤ n}, then</p>
		  <p>OpCreate(SS, iri) = SS union { NamedRepository(iri, R0)} if iri not in repositoryNames(SS); 
		  otherwise, OpCreate(SS, iri) = SS</p>
		  <p>
		  where DR is a repository, NR<sub>i</sub> are named repositories, iri is an IRI, and 
		  R0 is the "empty repository".
		  </p>		  
		  <p>Here is what the second option would look like:
          </p>
		  <p>
		  The corresponding "create" operation for <a>Stores</a> is a mutator operation on the mutable Store object.
		  </p>
		  <p><dfn>Store.create(self, iri)</dfn> has domain Store x IRI and is void.
		  </p>
		  <p class="ednote">The semantics of Store.create is to have the side-effect of 
             constructing a new Named Repository object with name iri whose initial content is empty, 
			 that is owned by the Store self.		  
		  </p>
		  <p class="ednote">We must defined the meaning of the "initial content of a (Named) Repository is empty" somewhere,
		  probably as a note to the definition of (Named) Repository.
		  </p>
		  <p class="ednote">Is "owned" the property term to use for the relationship between a Named Repository and
		  its parent Store?
		  </p>
		  <p>Here is what the third option would look like:
          </p>
		  <p>We extend the syntax of OpCreate to include the following additional signature:</p>
		  <ul>
		    <li>On the domain StoreState x IRI, the range is StoreState.</li>
		  </ul>
		  <p>The semantics of <a>OpCreate</a> on the domain extension is defined as follows.</p> 
		  <p>Let SS = {DD} union {(iri<sub>i</sub>, D<sub>i</sub>) | 1 ≤ i ≤ n} and 
		  repositoryNames(SS) = { iri<sub>i</sub> | 1 ≤ i ≤ n}, then</p>
		  <p>OpCreate(SS, iri) = SS union { (iri, {})} if iri not in repositoryNames(SS); 
		  otherwise, OpCreate(SS, iri) = SS</p>
		  <p>
		  where DD and D<sub>i</sub> are RDF Datasets, iri and iri<sub>i</sub> are IRIs.
		  </p>
         </section>
		-->
			<!--
		<section id="def-existing-update-operator">
          <h4>Operator</h4>
		  <p><dfn>Operator</dfn> is defined in [[!SPARQL11-Update]] as an Update Operation with the following signatures:</p>
		  <ul>
		    <li>On the domain X x Y, the range is Z.</li>
			<li>On the domain X x U, the range is V.</li>
		  </ul>	
		  <p class="ednote">The semantics of <a>Operator</a> is defined in [[!SPARQL11-Update]] to be (semantics)
		  </p>
    	</section>
		<section id="def-extension-of-existing-update-operator">
          <h4>Operator</h4>
		  <p><dfn>Operator</dfn> is defined in [[!SPARQL11-Update]] as a (supertype) with the following signatures:</p>
		  <ul>
		    <li>On the domain X x Y, the range is Z.</li>
			<li>On the domain X x U, the range is V.</li>
		  </ul>
		  <p>We extend the syntax of Operator to include the following additional signatures:</p>
		  <ul>
		    <li>On the domain X x Y, the range is Z.</li>
			<li>On the domain X x U, the range is V.</li>
		  </ul>
		  <p class="ednote">The semantics of <a>Operator</a> is defined in [[!SPARQL11-Update]] to be (semantics)
		  </p>
		  <p class="ednote">The intended semantics of <a>Operator</a> on the extended signature is (semantics)
		  </p>
		</section>
		<section id="def-new-operator">
          <h4>Operator</h4>
		  <p>A <dfn>Operator</dfn> is a (supertype) where (specialization)</a>.
		  </p>	
		  <p class="ednote">The intended semantics of <a>Operator</a> is (semantics)
		  </p>
		</section>
		-->
		</section>
		<section id="examples">
			<h2>Examples</h2>
			<section id="fhir-stream-example">
				<h3>FHIR RDF Stream Example</h3>
				<section id="fhir-graph-example">
					<aside class="example" id="ex-fhir-graph" title="FHIR Statements as RDF Graph">
						The following is a representation of an RDF graph in Trig. These statements
						have a dynamic aspect that is implicitly expressed in timestamps of the
						events of type fhir:Observations. Although the statements appear in a
						particular order within the graph representation, this order is not
						significant to inference. In particualr, the temporal order is not directly
						available through simple entailment. We will show how this same data could
						be handled within some of the new datatypes so that the dynamic nature of
						the statements is accessible through simple entailment. <p>The following
							graph is denoted G<sub>FHIR</sub>.</p>
						<pre>
@prefix fhir: &lt;http://hl7.org/fhir/&gt; .
@prefix lr: &lt;http://localhost/local-records#&gt; .
@prefix obs: &lt;http://hl7.org/fhir/Observation.&gt; .
@prefix prov: &lt;http://www.w3.org/ns/prov#&gt; .
@prefix sct: &lt;http://snomed.info/id/&gt; .

_:b1 a fhir:Observation ;
		obs:code sct:36407505 ;
		obs:device lr:sensor1234 ;
		obs:effectiveDateTime "2015-01-01T12:00:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt; ;
		obs:subject lr:patientA ;
		obs:valueQuantity _:b2 .
	
_:b2 lr:unit "bpm"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; ;
		lr:value "50"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt; .

_:b4 a fhir:Observation ;
		obs:code sct:36407505 ;
		obs:device lr:sensor1234 ;
		obs:effectiveDateTime "2015-01-01T12:01:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt; ;
		obs:subject lr:patientA ;
		obs:valueQuantity _:b5 .
	
_:b5 lr:unit "bpm"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; ;
		lr:value "53"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt; .

_:b7 a fhir:Observation ;
		obs:code sct:36407505 ;
		obs:device lr:sensor1234 ;
		obs:effectiveDateTime "2015-01-01T12:02:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt; ;
		obs:subject lr:patientA ;
		obs:valueQuantity _:b8 .
	
_:b8 lr:unit "bpm"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; ;
		lr:value "48"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt; .
</pre>
						<p>G<sub>FHIR</sub> is the union of three graphs, each fully describing an
							observation. We write:</p>
						<p>G<sub>FHIR</sub> = Dataset-UNION(Dataset-UNION(G<sub>1, FHIR</sub>,
								G<sub>2, FHIR</sub>), G<sub>3, FHIR</sub>)</p>
						<p>where G<sub>1, FHIR</sub> is: </p>
						<pre>
@prefix fhir: &lt;http://hl7.org/fhir/&gt; .
@prefix lr: &lt;http://localhost/local-records#&gt; .
@prefix obs: &lt;http://hl7.org/fhir/Observation.&gt; .
@prefix prov: &lt;http://www.w3.org/ns/prov#&gt; .
@prefix sct: &lt;http://snomed.info/id/&gt; .

_:b1 a fhir:Observation ;
		obs:effectiveDateTime "2015-01-01T12:00:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt; ;
		obs:code sct:36407505 ;
		obs:device lr:sensor1234 ;
		obs:subject lr:patientA ;
		obs:valueQuantity _:b2 .
	
_:b2 lr:unit "bpm"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; ;
		lr:value "50"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt; .
</pre>
						<p>G<sub>2, FHIR</sub> is:. </p>
						<pre>
@prefix fhir: &lt;http://hl7.org/fhir/&gt; .
@prefix lr: &lt;http://localhost/local-records#&gt; .
@prefix obs: &lt;http://hl7.org/fhir/Observation.&gt; .
@prefix prov: &lt;http://www.w3.org/ns/prov#&gt; .
@prefix sct: &lt;http://snomed.info/id/&gt; .


_:b4 a fhir:Observation ;
		obs:effectiveDateTime "2015-01-01T12:01:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt; ;
		obs:code sct:36407505 ;
		obs:device lr:sensor1234 ;
		obs:subject lr:patientA ;
		obs:valueQuantity _:b5 .
	
_:b5 lr:unit "bpm"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; ;
		lr:value "53"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt; .
</pre>
						<p>G<sub>3, FHIR</sub> is: </p>
						<pre>
@prefix fhir: &lt;http://hl7.org/fhir/&gt; .
@prefix lr: &lt;http://localhost/local-records#&gt; .
@prefix obs: &lt;http://hl7.org/fhir/Observation.&gt; .
@prefix prov: &lt;http://www.w3.org/ns/prov#&gt; .
@prefix sct: &lt;http://snomed.info/id/&gt; .

_:b7 a fhir:Observation ;
		obs:effectiveDateTime "2015-01-01T12:02:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt; ;
		obs:code sct:36407505 ;
		obs:device lr:sensor1234 ;
		obs:subject lr:patientA ;
		obs:valueQuantity _:b8 .
	
_:b8 lr:unit "bpm"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; ;
		lr:value "48"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt; .
</pre>
					</aside>
				</section>
				<aside class="example" id="ex-fhir-stream" title="FHIR Statements as RDF Stream">
					Recall that an <a>RDF Stream</a> is a sequence of <a>timestamped graphs</a>
					which are composed of a default graph and a named graph, where the default graph
					contains a distinguished triple called the timestamp triple. <p>We will
						construct an RDF Stream for the FHIR observation data, which as a whole is
						denoted S<sub>FHIR</sub>.</p>
					<p>Let G'<sub>1, FHIR</sub> be </p>
					<pre>
@prefix fhir: &lt;http://hl7.org/fhir/&gt; .
@prefix lr: &lt;http://localhost/local-records#&gt; .
@prefix obs: &lt;http://hl7.org/fhir/Observation.&gt; .
@prefix prov: &lt;http://www.w3.org/ns/prov#&gt; .
@prefix sct: &lt;http://snomed.info/id/&gt; .

_:b1 a fhir:Observation ;
		obs:code sct:36407505 ;
		obs:device lr:sensor1234 ;
		obs:subject lr:patientA ;
		obs:valueQuantity _:b2 .
	
_:b2 lr:unit "bpm"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; ;
		lr:value "50"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt; .
</pre>
					<p>which is like G<sub>1, FHIR</sub> except it is missing the timestamp triple,
						and TS<sub>1, FHIR</sub> be the timestamp triple</p>
					<pre>
_:b1 obs:effectiveDateTime "2015-01-01T12:00:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt;
</pre>
					<p>We construct a timestamped graph with the constructor <a>TSGraph</a></p>
					<p>TSG<sub>1, FHIR</sub> = <a>TSGraph</a>(TS<sub>1, FHIR</sub>, G'<sub>1,
							FHIR</sub>)</p>
					<p>Similarly,</p>
					<p>TSG<sub>i, FHIR</sub> = TSGraph(TS<sub>i, FHIR</sub>, G'<sub>i,
						FHIR</sub>)</p>
					<p>The RDF stream can be abstractly constructed from its component timestamped
						graphs using basic operations:</p>
					<p>S<sub>FHIR</sub> = Cons(TSG<sub>3, FHIR</sub>, Cons(TSG<sub>2, FHIR</sub>,
							Cons(TSG<sub>1, FHIR</sub>, S<sub>0</sub>))) </p>
					<p>where S<sub>0</sub> is the null sequence.</p>
					<p>One possible way that this RDF Stream would be transmitted is as a sequence
						of RDF documents, each one containing an RDF graph corresponding to one
						element of the stream, where the timestamp triple is the first triple in the
						document. </p>
				</aside>
				<aside class="example" id="ex-fhir-dataset" title="FHIR Statements as RDF Dataset">
					The information about FHIR observations can also be represented using the <a>RDF
						Dataset</a> datatype. The named graph structure allows the statements of
					each stream element to be grouped together, and also allows us to materialize,
					in the default graph, statements giving the order among these elements. <p>Let
							D<sub>0, FHIR</sub> be</p>
					<pre>
@prefix prov: &lt;http://www.w3.org/ns/prov#&gt; .

_:b102 prov:wasRevisionOf _:b101.
_:b103 prov:wasRevisionOf _:b102.
</pre>
					<p>We write</p>
					<p>D<sub>FHIR</sub> = Dataset-UNION(Dataset-UNION(Dataset-UNION(D<sub>0,
							FHIR</sub>, D<sub>1, FHIR</sub>), D<sub>2, FHIR</sub>), D<sub>3,
							FHIR</sub>)</p>
					<p>where</p>
					<p>D<sub>i, FHIR</sub> = Graph(b<sub>i, FHIR</sub>, G<sub>i, FHIR</sub>) and</p>
					<p>b<sub>1, FHIR</sub>= _:b101, b<sub>2, FHIR</sub>= _:b102, b<sub>3,
						FHIR</sub>= _:b103 .</p>
					<p>The resulting dataset D<sub>FHIR</sub> is as follows.</p>
					<pre>
@prefix fhir: &lt;http://hl7.org/fhir/&gt; .
@prefix lr: &lt;http://localhost/local-records#&gt; .
@prefix obs: &lt;http://hl7.org/fhir/Observation.&gt; .
@prefix prov: &lt;http://www.w3.org/ns/prov#&gt; .
@prefix sct: &lt;http://snomed.info/id/&gt; .

_:b102 prov:wasRevisionOf _:b101.
_:b103 prov:wasRevisionOf _:b102.
_:b101{
	    _:b1 a fhir:Observation ;
		    obs:code sct:36407505 ;
		    obs:device lr:sensor1234 ;
		    obs:effectiveDateTime "2015-01-01T12:00:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt; ;
		    obs:subject lr:patientA ;
		    obs:valueQuantity _:b2 .
	
	    _:b2 lr:unit "bpm"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; ;
		    lr:value "50"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt; .
}	

_:b102{
		_:b4 a fhir:Observation ;
			obs:code sct:36407505 ;
			obs:device lr:sensor1234 ;
			obs:effectiveDateTime "2015-01-01T12:01:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt; ;
			obs:subject lr:patientA ;
			obs:valueQuantity _:b5 .
	
		_:b5 lr:unit "bpm"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; ;
			lr:value "53"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt; .
}
_:b103{
		_:b7 a fhir:Observation ;
			obs:code sct:36407505 ;
			obs:device lr:sensor1234 ;
			obs:effectiveDateTime "2015-01-01T12:02:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt; ;
			obs:subject lr:patientA ;
			obs:valueQuantity _:b8 .
	
		_:b8 lr:unit "bpm"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; ;
			lr:value "48"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt; .
}
</pre>
				</aside>
				<aside class="example" id="ex-fhir-repository"
					title="FHIR Statements as a Repository"> The dataset above is a static structure
					representing the entailment, under the provenance regime, of a first-order
						<a>Repository</a>. We denote this repository as R<sub>FHIR</sub>. In this
					example, the default dataset of the repository is empty. <p>We write</p>
					<p>R<sub>FHIR</sub> = [{}, [D<sub>i,FHIR</sub>]<sub>i=1, 2, 3</sub>]</p>
					<p>The repository can be abstractly constructed from its component datasets
						using basic operations:</p>
					<p>R<sub>FHIR</sub> = Revise(D<sub>3,FHIR</sub>, Revise(D<sub>2,FHIR</sub>,
							Revise(D<sub>1,FHIR</sub>, S<sub>0</sub>))) </p>
					<p> Since the dynamic component of a repository may be lazily contructed, the
						repository could be transmitted as a sequence of documents, one for the
						static part and one for each of the elements of the dynamic part of the
						repository, transmitted as they become available. </p>
				</aside>
				<aside class="example" id="ex-fhir-repository"
					title="FHIR Statements as a Second-Order RDF Store">
					<p> The repository above has lost the information, contained in the stream, as
						to which is the timestamp triple of each timestamped graph. For this
						example, we can express that information as metadata for the entire
						repository, since it is sufficient to identify the timestamp predicate,
						because there is only one triple in the default graph of each timestamped
						graph that uses that predicate. Although this is a specialization of the RDF
						Stream structure, it would be the most common usecase. To attach this
						metadata to the repository as a whole, we name the repository and embed it
						in a second-order RDF Store. We denote this store as ST<sub>FHIR</sub>. </p>
					<p>We write</p>
					<p>ST<sub>FHIR</sub> = Dataset-UNION(ST<sub>FHIR, static</sub>, ST<sub>FHIR,
							dynamic</sub>)</p>
					<p>where</p>
					<p>ST<sub>FHIR, static</sub> = Static<sub>2</sub>(G<sub>eff</sub>, {_:b301},
						{_:b301 => R<sub>FHIR</sub>})</p>
					<p>where G<sub>eff</sub> is the graph containing the single triple</p>
					<pre>
@prefix rsp: &lt;http://@@@#&gt; .
@prefix obs: &lt;http://hl7.org/fhir/Observation.&gt; .

_:b301 rsp:usesTimestampPredicate obs:effectiveDateTime.
				</pre>
					<p>The dynamic part of the store ST can be abstractly constructed from its
						component datasets using basic operations:</p>
					<p>ST<sub>FHIR, dynamic</sub> = Cons(ST<sub>3,FHIR</sub>,
							Cons(ST<sub>2,FHIR</sub>, Cons(ST<sub>1,FHIR</sub>, S<sub>0</sub>))) </p>
					<p>where</p>
					<p> ST<sub>1, FHIR</sub> = [_:sv0, [_:b301, G<sub>1, FHIR</sub>, 1], 2]</p>
					<p> ST<sub>2, FHIR</sub> = [_:sv1, [_:b301, G<sub>2, FHIR</sub>, 1], 2]</p>
					<p> ST<sub>3, FHIR</sub> = [_:sv2, [_:b301, G<sub>3, FHIR</sub>, 1], 2]</p>
					<p>or generically</p>
					<p> ST<sub>i, FHIR</sub> = Static<sub>2</sub>({}, {stver<sub>i</sub>},
							{stver<sub>i</sub> => Static<sub>1</sub>({}, {_:b301}, {_:b301 =>
							G<sub>i, FHIR</sub>})})</p>
					<p>where stver<sub>1</sub> = _:sv0, stver<sub>2</sub> = _:sv1, stver<sub>3</sub>
						= _:sv2.</p>
					<p>To construct a store in this fashion, it is necessary to ensure
						synchronization of the store and repository versions manually. A more
						reliable method is to use the store constructor
						<a>Store<sub>k</sub></a>.</p>
				</aside>
			</section>
			<section id="fhir-motion">
				<h3>Example of a Store Holding Two RDF Streams</h3>
				<aside class="example" id="ex-motion-graphs"
					title="FHIR Motion Observations as Graphs"> We model a second stream of FHIR
					observation data using the graphs below. <p>Let G<sub>1, FHIR-m</sub> be: </p>
					<pre>
@prefix fhir: &lt;http://hl7.org/fhir/> .
@prefix lr: &lt;http://localhost/local-records#> .
@prefix sct: &lt;http://snomed.info/id/> .
@prefix obs: &lt;http://hl7.org/fhir/Observation.> .
@prefix prov: &lt;http://www.w3.org/ns/prov#> .

	

_:m1 a fhir:Observation ;
		obs:code sct:251833007 ;
		obs:device lr:sensor5678 ;
		obs:effectiveDateTime "2015-01-01T12:00:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp> ;
		obs:subject lr:patientA ;
		obs:valueQuantity _:m2 .
	
_:m2 lr:unit "kJ"^^&lt;http://www.w3.org/2001/XMLSchema#string> ;
		lr:value "93"^^&lt;http://www.w3.org/2001/XMLSchema#integer> .
</pre>
					<p>Let G<sub>2, FHIR-m</sub> be: </p>
					<pre>
@prefix fhir: &lt;http://hl7.org/fhir/> .
@prefix lr: &lt;http://localhost/local-records#> .
@prefix sct: &lt;http://snomed.info/id/> .
@prefix obs: &lt;http://hl7.org/fhir/Observation.> .
@prefix prov: &lt;http://www.w3.org/ns/prov#> .

	

_:m4 a fhir:Observation ;
		obs:code sct:251833007 ;
		obs:device lr:sensor5678 ;
		obs:effectiveDateTime "2015-01-01T12:02:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp> ;
		obs:subject lr:patientA ;
		obs:valueQuantity _:m5 .
	
_:m5 lr:unit "kJ"^^&lt;http://www.w3.org/2001/XMLSchema#string> ;
		lr:value "127"^^&lt;http://www.w3.org/2001/XMLSchema#integer> .
</pre>
					<p>Let G<sub>3, FHIR-m</sub> be: </p>
					<pre>
@prefix fhir: &lt;http://hl7.org/fhir/> .
@prefix lr: &lt;http://localhost/local-records#> .
@prefix sct: &lt;http://snomed.info/id/> .
@prefix obs: &lt;http://hl7.org/fhir/Observation.> .
@prefix prov: &lt;http://www.w3.org/ns/prov#> .

	

_:m7 a fhir:Observation ;
		obs:code sct:251833007 ;
		obs:device lr:sensor5678 ;
		obs:effectiveDateTime "2015-01-01T12:04:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp> ;
		obs:subject lr:patientA ;
		obs:valueQuantity _:m8 .
	
_:m8 lr:unit "kJ"^^&lt;http://www.w3.org/2001/XMLSchema#string> ;
		lr:value "45"^^&lt;http://www.w3.org/2001/XMLSchema#integer> .
</pre>
				</aside>
				<aside class="example" id="ex-motion-datasets"
					title="FHIR Motion Observations as Datasets">
					<p>Let</p>
					<p>D<sub>i, FHIR-m</sub> = Graph(b<sub>i, FHIR-m</sub>, G<sub>i,
						FHIR-m</sub>)</p>
					<p>where b<sub>1, FHIR-m</sub>= _:m0, b<sub>2, FHIR-m</sub>= _:m3, b<sub>3,
							FHIR-m</sub>= _:m6</p>
				</aside>
				<aside class="example" id="ex-motion-repository"
					title="FHIR Motion Observations as Repository">
					<p>Let</p>
					<p>R<sub>FHIR-m</sub> = [{}, [D<sub>i,FHIR-m</sub>]<sub>i=1, 2, 3</sub>]</p>
				</aside>
				<aside class="example" id="ex-graph-timestamp-pred-two"
					title="Metadata Stating Timestamp Predicate for Two Streams"><p> As in the
						previous example of a store holding an RDF Stream, we use the default
						repository of the store to hold the metadata regarding timestamp predicates.
						Let G<sub>eff, 2</sub> be the graph </p>
					<pre>
@prefix rsp: &lt;http://@@@#&gt; .
@prefix obs: &lt;http://hl7.org/fhir/Observation.&gt; .

_:rn1 rsp:usesTimestampPredicate obs:effectiveDateTime.
_:rn2 rsp:usesTimestampPredicate obs:effectiveDateTime.
				</pre>
				</aside>
				<aside class="example" id="ex-store-fhir-two"
					title="Store containing Two FHIR Streams">
					<p>We build a second-order store ST<sub>FHIR, 2</sub> from the first-order
						repositories R<sub>FHIR</sub> and R<sub>FHIR-m</sub> defined above. This is
						done using the Store<sub>2</sub> constructor. The arguments of the
							Store<sub>2</sub> constructor are as follows. </p>
					<ul>
						<li>The default first-order repository of the store, which in this case has
							default graph G<sub>eff, 2</sub> and no versions. .</li>
						<li>The set of repository names, {_:rn1, _:rn2}.</li>
						<li>The mapping from repository names to first-order repositories, {_:rn1 =>
								R<sub>FHIR</sub>, _:rn2 => R<sub>FHIR-m</sub>} </li>
						<li>The set of store version names {_:sv0, _:sv1, _:sv2, _:sv3}</li>
						<li>The partial functions from store version names onto repository version
							names. <ul>
								<li>The repository R<sub>FHIR</sub> (named _:rn1 in this store) has
									version names {_:b101, _:b102, _:b103}. For this repository, we
									assign to _:rn1 the mapping M<sub>_:rn1</sub> = {_:sv0 =>
									_:b101, _:sv1 => _:b102, _:sv2 => _:b103}. Notice that the
									domain is a proper interval subset of the set of store version
									names.</li>
								<li>The repository R<sub>FHIR-m</sub> (named _:rn2 in this store)
									has version names {_:m101, _:m102, _:m103}. For this repository,
									we assign to _:rn2 the mapping M<sub>_:rn2</sub> = {_:sv0 =>
									_:m101, _:sv1 => _:m101, _:sv2 => _:m102, _:sv3 => _:m103}.
									Notice that the domain of this mapping is the full set of store
									version names.</li>
							</ul>
						</li>
					</ul>
					<p>The mappings from store version names to repository version names are
						constructed so that the two streams are aligned within the store with regard
						to their timestamps. Since the two streams use the same timestamp predicate,
						this alignment sets up a query that creates a union of the two streams into
						one stream containing both FHIR observations, when available, using the same
						timestamp predicate.</p>
					<p>The store may also be continuously queried with matching performed against
						both streams without actually constructing an intermediate stream union. See
						the query example <a href="ex-store-query">Example !!!</a>.</p>
				</aside>
			</section>
			<section id="general-stream-example">
				<h3>General RDF Stream Example</h3>
				<aside class="example" id="ex-prov-dataset"
					title="FHIR Provenance in an RDF Dataset"> We consider a more general RDF Stream
					example, showing a typical case when sets of statements have multiple temporal
					characteristics. We construct a set of named graphs <p>NG<sub>i, FHIR</sub> =
							Graph(nb<sub>i</sub>, G<sub>i, FHIR</sub>)</p> where <p>nb<sub>1</sub> =
						_:b0, nb<sub>2</sub> = _:b3, nb<sub>3</sub> = _:b6 </p> and we express some
					provenance metadata using these graph names. Let G<sub>1, prov</sub> be
					<pre>
@prefix lr: &lt;http://localhost/local-records#&gt; .
@prefix prov: &lt;http://www.w3.org/ns/prov#&gt; .

_:b0 
	prov:generatedAtTime "2015-01-01T12:00:33Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; ;
    lr:stream lr:streamA12342015-01-01T12:00:00Z .
</pre>
					Let G<sub>2, prov</sub> be
					<pre>
@prefix lr: &lt;http://localhost/local-records#&gt; .
@prefix prov: &lt;http://www.w3.org/ns/prov#&gt; .

_:b3 
	prov:generatedAtTime "2015-01-01T12:01:45Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; ;
    lr:stream lr:streamA12342015-01-01T12:00:00Z .
</pre>
					Let G<sub>3, prov</sub> be
					<pre>
@prefix lr: &lt;http://localhost/local-records#&gt; .
@prefix prov: &lt;http://www.w3.org/ns/prov#&gt; .

_:b6 
	prov:generatedAtTime "2015-01-01T12:02:54Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; ;
    lr:stream lr:streamA12342015-01-01T12:00:00Z .
</pre>
					In this example, we have the time of observation as one temporal
					characteristics, and the time the observation report was generated as the second
					temporal characteristic, The entire dataset is denoted D<sub>prov</sub> and is
					constructed as follows <p>D<sub>prov</sub> = Dataset-UNION(
							Dataset-UNION(D<sub>1,prov</sub>, D<sub>2,prov</sub>),
							D<sub>3,prov</sub> ) </p> where <p> D<sub>i,prov</sub> =
							Dataset-UNION(G<sub>i, prov</sub>, NG<sub>i, FHIR</sub>) </p> The
					following is a representation of D<sub>prov</sub> in Trig. In this
					representation, the dytnamic aspects are implicitly expressed in timestamps, but
					the temporal order is not directly available through simple entailment.
					<pre>
@prefix fhir: &lt;http://hl7.org/fhir/&gt; .
@prefix lr: &lt;http://localhost/local-records#&gt; .
@prefix obs: &lt;http://hl7.org/fhir/Observation.&gt; .
@prefix prov: &lt;http://www.w3.org/ns/prov#&gt; .
@prefix sct: &lt;http://snomed.info/id/&gt; .

_:b0 
	prov:generatedAtTime "2015-01-01T12:00:33Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; ;
    lr:stream lr:streamA12342015-01-01T12:00:00Z .
_:b0 {
	_:b1 a fhir:Observation ;
		obs:code sct:36407505 ;
		obs:device lr:sensor1234 ;
		obs:effectiveDateTime "2015-01-01T12:00:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt; ;
		obs:subject lr:patientA ;
		obs:valueQuantity _:b2 .
	
	_:b2 lr:unit "bpm"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; ;
		lr:value "50"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt; .
}

_:b3 
	prov:generatedAtTime "2015-01-01T12:01:45Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; ;
    lr:stream lr:streamA12342015-01-01T12:00:00Z .
_:b3 {
	_:b4 a fhir:Observation ;
		obs:code sct:36407505 ;
		obs:device lr:sensor1234 ;
		obs:effectiveDateTime "2015-01-01T12:01:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt; ;
		obs:subject lr:patientA ;
		obs:valueQuantity _:b5 .
	
	_:b5 lr:unit "bpm"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; ;
		lr:value "53"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt; .
}

_:b6 
	prov:generatedAtTime "2015-01-01T12:02:54Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; ;
    lr:stream lr:streamA12342015-01-01T12:00:00Z .
_:b6 {
	_:b7 a fhir:Observation ;
		obs:code sct:36407505 ;
		obs:device lr:sensor1234 ;
		obs:effectiveDateTime "2015-01-01T12:02:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt; ;
		obs:subject lr:patientA ;
		obs:valueQuantity _:b8 .
	
	_:b8 lr:unit "bpm"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; ;
		lr:value "48"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt; .
}
</pre>
				</aside>
				<aside class="example" id="ex-prov-stream" title="FHIR Provenance in an RDF Stream">
					<p>The representation of this same information as an RDF Stream takes the form
						of the following sequence. The stream as a whole is denoted
						S<sub>prov</sub>. </p>
					<p>We write</p>
					<p>S<sub>prov</sub> = [TSG<sub>i,prov</sub>]<sub>i=1, 2, 3</sub></p>
					<p>A representation of the first element of the stream is a timestamped graph as
						follows.</p>
					<p>TSG<sub>i,prov</sub> = TSGraph(, D'<sub>i, prov</sub>)</p> where D'<sub>i,
						prov</sub> is like D<sub>i, prov</sub> except it is missing the timestamp
					triple. <p>D'<sub>i, prov</sub> = Dataset-DIFF(D<sub>i, prov</sub>, TS<sub>i,
							prov</sub>) </p> where TS<sub>1, prov</sub> is <pre>
@prefix prov: &lt;http://www.w3.org/ns/prov#&gt; .

_:b0 
	prov:generatedAtTime "2015-01-01T12:00:33Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; ;
</pre>
					<p>and so on.</p>
					<p>One possible way that this RDF Stream would be transmitted is as a sequence
						of RDF documents, each one containing an RDF Dataset corresponding to one
						element of the stream.</p>
					<p>In this example, each element of the stream contains a triple in its default
						graph that provides an identifier for the stream as a whole
							(<code>lr:streamA12342015-01-01T12:00:00Z</code>). This is optional for
						RDF streams.</p>
				</aside>
				<aside class="example" id="ex-prov-dataset-2"
					title="FHIR Provenance in a Second-Order Dataset"> This data can also be
					represented using the second-order <a>Dataset</a> datatype. For this
					representation, we use an extension of the Trig syntax to "quints". This
					additional name allows the statements of each stream element to be grouped
					together, and also allows us to materialize, in the default (first-order)
					dataset, statements giving the order among these elements. The second-order
					dataset is denoted D2<sub>prov</sub>. <pre>
@prefix fhir: &lt;http://hl7.org/fhir/&gt; .
@prefix lr: &lt;http://localhost/local-records#&gt; .
@prefix obs: &lt;http://hl7.org/fhir/Observation.&gt; .
@prefix prov: &lt;http://www.w3.org/ns/prov#&gt; .
@prefix sct: &lt;http://snomed.info/id/&gt; .

_:b202 prov:wasRevisionOf _:b201.
_:b203 prov:wasRevisionOf _:b202.

_:b201{
    DEFAULT {
		_:b0 
			prov:generatedAtTime "2015-01-01T12:00:33Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; ;
			lr:stream lr:streamA12342015-01-01T12:00:00Zm .
	}
    _:b0 {
	    _:b1 a fhir:Observation ;
		    obs:code sct:36407505 ;
		    obs:device lr:sensor1234 ;
		    obs:effectiveDateTime "2015-01-01T12:00:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt; ;
		    obs:subject lr:patientA ;
		    obs:valueQuantity _:b2 .
	
	    _:b2 lr:unit "bpm"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; ;
		    lr:value "50"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt; .
    }
}	

_:b202{
    DEFAULT {
		_:b3 
			prov:generatedAtTime "2015-01-01T12:01:45Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; ;
			lr:stream lr:streamA12342015-01-01T12:00:00Z .
	}
	_:b3 {
		_:b4 a fhir:Observation ;
			obs:code sct:36407505 ;
			obs:device lr:sensor1234 ;
			obs:effectiveDateTime "2015-01-01T12:01:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt; ;
			obs:subject lr:patientA ;
			obs:valueQuantity _:b5 .
	
		_:b5 lr:unit "bpm"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; ;
			lr:value "53"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt; .
	}
}
_:b203{
    DEFAULT {
		_:b6 
			prov:generatedAtTime "2015-01-01T12:02:54Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; ;
			lr:stream lr:streamA12342015-01-01T12:00:00Z .
	}
	_:b6 {
		_:b7 a fhir:Observation ;
			obs:code sct:36407505 ;
			obs:device lr:sensor1234 ;
			obs:effectiveDateTime "2015-01-01T12:02:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt; ;
			obs:subject lr:patientA ;
			obs:valueQuantity _:b8 .
	
		_:b8 lr:unit "bpm"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; ;
			lr:value "48"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt; .
	}
}
</pre>
					<p>We write</p>
					<p>D2<sub>prov</sub> = Dataset-UNION( Dataset-UNION( Dataset-UNION(
							Dataset-UNION(D<sub>0, prov</sub>,ND<sub>1, prov</sub>),ND<sub>2,
							prov</sub>),ND<sub>3, prov</sub>) </p>
					<p>where</p>
					<p>ND<sub>i, prov</sub> = Dataset( b<sub>i, prov</sub>, D<sub>i, prov</sub>)</p>
					<p>b<sub>1, prov</sub>= _:b201, b<sub>2, prov</sub>= _:b202, b<sub>3,
						prov</sub>= _:b203 .</p>
					<p>and</p>
					<p>D<sub>0, prov</sub> is</p>
					<pre>
@prefix prov: &lt;http://www.w3.org/ns/prov#&gt; .

_:b202 prov:wasRevisionOf _:b201.
_:b203 prov:wasRevisionOf _:b202.
</pre>
				</aside>
				<aside class="example" id="ex-psrov-repository"
					title="FHIR Provenance as a Second-Order Repository">
					<p> The second-order dataset above is a static structure representing the
						entailment, under the provenance regime, of a second-order
						<a>Repository</a>. The repository as a whole is denoted R<sub>prov</sub>. In
						this example, the default dataset of the repository is empty. </p>
					<p>We write</p>
					<p>R<sub>prov</sub> = {} ∪ [ND<sub>i,prov</sub>]<sub>i=1, 2, 3</sub></p>
					<p> For this representation, we use the same extension of the Trig syntax to
						"quints" as in the previous example. Since repositories are dynamic
						entities, one form of the transmission of the repository would be a sequence
						of documents representing named first-order datasets, as shown below. </p>
					<p>The first document of the sequence is as follows. The named dataset is
						denoted ND<sub>1, prov</sub>. </p>
					<pre>
@prefix fhir: &lt;http://hl7.org/fhir/&gt; .
@prefix lr: &lt;http://localhost/local-records#&gt; .
@prefix obs: &lt;http://hl7.org/fhir/Observation.&gt; .
@prefix prov: &lt;http://www.w3.org/ns/prov#&gt; .
@prefix sct: &lt;http://snomed.info/id/&gt; .

_:b201{
    DEFAULT {
		_:b0 
			prov:generatedAtTime "2015-01-01T12:00:33Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; ;
			lr:stream lr:streamA12342015-01-01T12:00:00Zm .
	}
    _:b0 {
	    _:b1 a fhir:Observation ;
		    obs:code sct:36407505 ;
		    obs:device lr:sensor1234 ;
		    obs:effectiveDateTime "2015-01-01T12:00:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt; ;
		    obs:subject lr:patientA ;
		    obs:valueQuantity _:b2 .
	
	    _:b2 lr:unit "bpm"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; ;
		    lr:value "50"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt; .
    }
}	
</pre>
					<p>The second document of the sequence is as follows. The named dataset is
						denoted ND<sub>2, prov</sub>. </p>
					<pre>
@prefix fhir: &lt;http://hl7.org/fhir/&gt; .
@prefix lr: &lt;http://localhost/local-records#&gt; .
@prefix obs: &lt;http://hl7.org/fhir/Observation.&gt; .
@prefix prov: &lt;http://www.w3.org/ns/prov#&gt; .
@prefix sct: &lt;http://snomed.info/id/&gt; .

_:b202{
    DEFAULT {
		_:b3 
			prov:generatedAtTime "2015-01-01T12:01:45Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; ;
			lr:stream lr:streamA12342015-01-01T12:00:00Z .
	}
	_:b3 {
		_:b4 a fhir:Observation ;
			obs:code sct:36407505 ;
			obs:device lr:sensor1234 ;
			obs:effectiveDateTime "2015-01-01T12:01:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt; ;
			obs:subject lr:patientA ;
			obs:valueQuantity _:b5 .
	
		_:b5 lr:unit "bpm"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; ;
			lr:value "53"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt; .
	}
}
</pre>
					<p>The third document of the sequence is as follows. The named dataset is
						denoted ND<sub>3, prov</sub>. </p>
					<pre>
@prefix fhir: &lt;http://hl7.org/fhir/&gt; .
@prefix lr: &lt;http://localhost/local-records#&gt; .
@prefix obs: &lt;http://hl7.org/fhir/Observation.&gt; .
@prefix prov: &lt;http://www.w3.org/ns/prov#&gt; .
@prefix sct: &lt;http://snomed.info/id/&gt; .

_:b203{
    DEFAULT {
		_:b6 
			prov:generatedAtTime "2015-01-01T12:02:54Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; ;
			lr:stream lr:streamA12342015-01-01T12:00:00Z .
	}
	_:b6 {
		_:b7 a fhir:Observation ;
			obs:code sct:36407505 ;
			obs:device lr:sensor1234 ;
			obs:effectiveDateTime "2015-01-01T12:02:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt; ;
			obs:subject lr:patientA ;
			obs:valueQuantity _:b8 .
	
		_:b8 lr:unit "bpm"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; ;
			lr:value "48"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt; .
	}
}
</pre>
				</aside>
			</section>
			<section id="pattern-examples">
				<h3>Pattern Examples</h3>
				<aside class="example" id="ex-bgp-fhir-heartrate"
					title="Basic Graph Pattern for FHIR Heartrate Observation">
					<p>The basic graph pattern (BGP) below will be used to demonstrate how solution
						mappings might be extracted from the above data structures. This BGP is
						denoted TP<sub>FHIR-heartrate</sub>. </p>
					<pre>
?heartRateObservation a fhir:Observation ;
          obs:subject ?patient ;
          obs:effectiveDateTime ?heartRate_time ;
          obs:code &lt;http://snomed.info/sct:36407505&gt; ; # heart rate
          obs:valueQuantity [ fhir:Quantity.value ?heartRate;
                              fhir:Quantity.unit 'bpm'        ] .
</pre>
				</aside>
				<aside class="example" id="ex-bgp-pattern-prov-revise"
					title="Basic Graph Pattern for Revision Statements">
					<p>The basic graph pattern (BGP) below will be used to demonstrate how solution
						mappings about the relative order of versions of a repository might be
						extracted from the above data structures using the provenance entailment
						regime. This BGP is denoted TP<sub>revise</sub>. </p>
					<pre>
?version prov:wasRevisionOf ?previous.
</pre>
				</aside>
				<aside class="example" id="ex-bgp-pattern-prov-initial"
					title="Basic Graph Pattern for Initial Version Statements">
					<p>The basic graph pattern (BGP) below will be used to demonstrate how solution
						mappings describing the initial version of a repository might be extracted
						from the above data structures using the provenance entailment regime. This
						BGP is denoted TP<sub>initialVersion</sub>. </p>
					<pre>
?version repo:isInitialVersion "true"^^&lt;http://www.w3.org/2001/XMLSchema#boolean&gt; .
</pre>
				</aside>
				<aside class="example" id="ex-bgp-pattern-prov-initial-of"
					title="Basic Graph Pattern for Initial Version Statements for Named Repositories">
					<p>The basic graph pattern (BGP) below will be used to demonstrate how solution
						mappings describing the initial version of a named repository might be
						extracted from the above data structures using the provenance entailment
						regime. This BGP is denoted TP<sub>initialVersionOf</sub>. </p>
					<pre>
?version repo:isInitialVersionOf ?repo .
</pre>
				</aside>
				<aside class="example" id="ex-bgp-pattern-prov-terminal"
					title="Basic Graph Pattern for Terminal Version Statements">
					<p>The basic graph pattern (BGP) below will be used to demonstrate how solution
						mappings describing the terminal version of a repository might be extracted
						from the above data structures using the repository structure entailment
						regime. This BGP is denoted TP<sub>terminalVersion</sub>. </p>
					<pre>
?version repo:isTerminalVersion "true"^^&lt;http://www.w3.org/2001/XMLSchema#boolean&gt; .
</pre>
				</aside>
				<aside class="example" id="ex-bgp-pattern-prov-terminal-of"
					title="Basic Graph Pattern for Terminal Version Statements for Named Repositories">
					<p>The basic graph pattern (BGP) below will be used to demonstrate how solution
						mappings describing the terminal version of a named repository might be
						extracted from the above data structures using the repository structure
						entailment regime. This BGP is denoted TP<sub>terminalVersionOf</sub>. </p>
					<pre>
?version repo:isTerminalVersionOf ?repo .
</pre>
				</aside>
				<aside class="example" id="ex-quad-fhir-heartrate"
					title="QuadPattern for FHIR Heartrate Observation">
					<p>The <a>Quadpattern</a> below will be used to demonstrate how solution
						mappings might be extracted from the above data structures. This
							<a>Quadpattern</a> is denoted QP<sub>FHIR-heartrate</sub>. </p>
					<pre>
GRAPH ?g {
	?heartRateObservation a fhir:Observation ;
          obs:subject ?patient ;
          obs:effectiveDateTime ?heartRate_time ;
          obs:code &lt;http://snomed.info/sct:36407505&gt; ; # heart rate
          obs:valueQuantity [ fhir:Quantity.value ?heartRate;
                              fhir:Quantity.unit 'bpm'        ] .
}
</pre>
					<p>We write</p>
					<p>QP<sub>FHIR-heartrate</sub> = Graph( ?g, TP<sub>FHIR-heartrate</sub>) </p>
				</aside>
				<aside class="example" id="ex-id-pattern-0"
					title="Identity Pattern for Zeroth Order"> This BGP is denoted IDP<sub>0</sub>.
					<pre>
{?s ?p ?o.}
</pre> The abstract algebra expression is <p> IDP<sub>0</sub>
						= BGP(?s ?p ?o) </p>
				</aside>
				<aside class="example" id="ex-id-pattern-1" title="Identity Pattern for First Order"
					> This GraphPattern is denoted IDP<sub>1</sub>.
					<pre>
{ graph ?g {?s ?p ?o} } union {?s ?p ?o}
</pre> The abstract algebra
					expression is <p> IDP<sub>1</sub> = Union( Graph( ?g, IDP<sub>0</sub> ),
							IDP<sub>0</sub>) </p>
				</aside>
				<aside class="example" id="ex-id-pattern-2"
					title="Identity Pattern for Second Order"> This DatasetPattern is denoted
						IDP<sub>2</sub>.
					<pre>
	{ dataset ?d { { graph ?g {?s ?p ?o} } union {?s ?p ?o} } }    
	 union
	{ graph ?g {?s ?p ?o} } union {?s ?p ?o}
</pre>
					The abstract algebra expression is <p> IDP<sub>2</sub> = Union( Dataset( ?d,
							IDP<sub>1</sub> ), IDP<sub>1</sub>) </p> and in general <p>
							IDP<sub>k+1</sub> = Union( Dataset( ?d, IDP<sub>k</sub> ),
							IDP<sub>k</sub>) </p>
				</aside>
			</section>
			<section id="query-examples">
				<h3>Query Examples</h3>
				<aside class="example" id="ex-select-triple-pattern-avg-hr"
					title="Select Query with Triple Pattern for Average Heartrate">
					<pre>
	
SELECT (AVG(?heartRate) AS ?heartRate_base)

WHERE {
        ?heartRateObservation a fhir:Observation ;
          obs:subject ?patient ;
          obs:effectiveDateTime ?heartRate_time ;
          obs:code &lt;http://snomed.info/sct:36407505&gt; ; # heart rate
          obs:valueQuantity [ fhir:Quantity.value ?heartRate;
                              fhir:Quantity.unit 'bpm'        ] .
        FILTER ( ?heartRate_time &gt;= (now() - 'P30D'^^xsd:dayTimeDuration) )
    }
</pre>
				</aside>
			</section>
			<section id="abstract-algebra-examples">
				<h3>Abstract Algebra Examples</h3>
				<section id="eval-examples">
					<h4>Eval</h4>
					<aside class="example" id="ex-match-bgp-dataset"
						title="Matching a BGP Against a k-th Order Dataset">
						<p>If k=0, then application of eval to a dataset and BGP corresponds to
							matching a BGP against an RDF Graph.</p>
						<p>If k=1, then application of eval to a dataset and BGP corresponds to
							matching a BGP against an RDF Dataset, so that the default graph is
							active.</p>
						<p>If k=2, then application of eval to a dataset and BGP corresponds to
							matching a BGP against the RDF Dataset that is the default dataset of
							the second-order dataset. For example,</p>
						<p> eval(<a href="#prov-dataset-2">D2<sub>prov</sub></a>, <a
								href="#bgp-pattern-prov-revise">TP<sub>rev</sub></a>) =
								Ω<sub>rev</sub>
						</p>
						<p> where Ω<sub>rev</sub> is shown in the following table:</p>
						<table id="omega-rev">
							<tr>
								<th>?version</th>
								<th>?previous</th>
							</tr>
							<tr>
								<td>_:b202</td>
								<td>_:b201</td>
							</tr>
							<tr>
								<td>_:b203</td>
								<td>_:b202</td>
							</tr>
						</table>
					</aside>
					<aside class="example" id="ex-match-bgp-repository"
						title="Matching a BGP Against a k-th Order Repository">
						<p>If k=0, then application of eval to a repository and BGP corresponds to
							matching the BGP against an RDF Graph, as defined in [[!SPARQL11-Query]]
							.</p>
						<p>If k=1, then application of eval to a repository and BGP corresponds to
							matching the BGP against the RDF Graph that is the static component of
							the first-order repository.</p>
						<p>For example,</p>
						<p> eval(<a href="#prov-dataset-2">D2<sub>prov</sub></a>, <a
								href="#bgp-pattern-prov-revise">TP<sub>rev</sub></a>) = <a
								href="#omega-rev">Ω<sub>rev</sub></a>
						</p>
						<p>If k=2, then application of eval to a repository and BGP corresponds to
							matching the BGP against the RDF Dataset that is the static component of
							the second-order repository.</p>
						<p>In general, application of eval to a (k+1)-th repository and BGP
							corresponds to matching the BGP against the k-th order RDF Dataset that
							is the static component of the input repository. The result is a
							multiset of solution mappings.</p>
					</aside>
					<aside class="example" id="ex-match-quad-dataset"
						title="Matching a QuadPattern Against a k-th Order Dataset">
						<p>Recall that a <a>QuadPattern</a>, also called a GraphGraphPattern, can
							match within named and unnamed graphs, depending on the nature of the
							pattern.</p>
						<p>If k=0, then application of eval to a dataset and QuadPattern corresponds
							to matching a QuadPattern against an RDF Graph, as defined in
							[[!SPARQL11-Query]].</p>
						<p>If k=1, then application of eval to a dataset and QuadPattern corresponds
							to matching a QuadPattern against an RDF Dataset, also as defined in
							[[!SPARQL11-Query]]. Such an operation can extract information from both
							the default and named components of the dataset. </p>
						<p>If k>=2, then application of eval to a dataset and QuadPattern
							corresponds to matching the QuadPattern against the default (k-1)-th
							order RDF Dataset of the input dataset, which may be defined by
							induction over the order. As shown in the next example, a second-order
							pattern (containing "quint" patterns) is needed to access the
							information in the (non-default) named components of a second-order
							dataset. </p>
					</aside>
					<aside class="example" id="ex-match-quint-second-order-dataset"
						title="Matching a Second-Order Pattern Against a Second-Order Dataset">
						<p> eval(<a href="#prov-dataset-2">D2<sub>prov</sub></a>, <a
								href="#id-pattern-2">IDP<sub>2</sub></a>) = Ω<sub>D2-prov</sub>
						</p>
						<p> where Ω<sub>D2-prov</sub> is partially shown in the following table:</p>
						<table id="omega-d2-prov">
							<tr>
								<th>?s</th>
								<th>?p</th>
								<th>?o</th>
								<th>?g</th>
								<th>?d</th>
							</tr>
							<tr>
								<td>_:b202</td>
								<td>prov:wasRevisionOf</td>
								<td>_:b201</td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>_:b0</td>
								<td>prov:generatedAtTime</td>
								<td>"2015-01-01T12:00:33Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt;</td>
								<td></td>
								<td>_:b201</td>
							</tr>
							<tr>
								<td>_:b1</td>
								<td>rdf:type</td>
								<td>fhir:Observation</td>
								<td>_:b0</td>
								<td>_:b201</td>
							</tr>
						</table>
					</aside>
					<aside class="example" id="ex-match-quad-first-order-repository"
						title="Matching a First-Order Pattern Against a First-Order Repository">
						<p>Recall the definition of the FHIR repository, which has an empty default
							dataset.</p>
						<p>R<sub>FHIR</sub> = [{}, [D<sub>i,FHIR</sub>]<sub>i=1, 2, 3</sub>]</p>
						<p>If we apply the first-order identity pattern IDP<sub>1</sub> to this
							repository, we obtain the following result structure.</p>
						<p> eval(<a href="#fhir-repository">R<sub>FHIR</sub></a>, <a
								href="#id-pattern-1">IDP<sub>1</sub></a>) = [{} , [Ω<sub>i,
								R-FHIR</sub>]<sub>i=1,2,3</sub>] </p>
						<p> where Ω<sub>i, R-FHIR</sub> = eval( D<sub>i, FHIR</sub>,
							IDP<sub>1</sub>) </p>
						<!--is partially shown in the following table:</p>
		<table id="omega-d2-prov">
			<tr>
				<th>?s</th>
				<th>?p</th>
				<th>?o</th>
				<th>?g</th>
				<th>?d</th>
			</tr>
			<tr>
				<td>_:b202</td>
				<td>prov:wasRevisionOf</td>
				<td>_:b201</td>
				<td></td>
				<td></td>
			</tr>
			<tr>
				<td>_:b0</td>
				<td>prov:generatedAtTime</td>
				<td>"2015-01-01T12:00:33Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt;</td>
				<td></td>
				<td>_:b201</td>
			</tr>
			<tr>
				<td>_:b1</td>
				<td>rdf:type</td>
				<td>fhir:Observation</td>
				<td>_:b0</td>
				<td>_:b201</td>
			</tr>
		</table>-->
					</aside>
					<!--
	 The Eval function has been extended to apply to higher-order datasets, repositories and stores.
     If the pattern is a BGP, then matching will be performed only within the default component 
	 (dataset, repository or store, as the case may be.)
	 <p>The multiset of solution mappings that is obtained by applying the BGP 
	 <a href='#bgp-pattern-prov-revise'>TP<sub>rev</sub></a> to the second-order dataset <a href='#prov-dataset-2'>D2<sub>prov</sub></a> is
	 shown in the following table, and is denoted Ω<sub>rev</sub>.
	 </p>
	 Application of the same BGP to the second-order <a>repository</a> <a href="#fhir-repository">R<sub>prov</sub></a>
	 under the simple entailment regime
	 results in an empty set of solution mappings.
	 <p>Eval(R<sub>prov</sub>, TP<sub>rev</sub>) = {}</p>
	 However, the solutions above are obtained under the provenance entailment regime
	 <p>Eval-Prov(R<sub>prov</sub>, TP<sub>rev</sub>) = Ω<sub>rev</sub></p>
	</aside>
	<p class="ednote">OK, the extension of the eval function has not actually been defined yet.</p>
     <aside class="example" id="ex-match-quad-pattern" title="Matching a QuadPattern">
     If the pattern is a quad pattern, then matching will be performed according to two cases.
	 <ul>
	   <li>If the data structure  (dataset, repository, or store) is of first-order, then the quad pattern
	   will be applied to named components.
	   </li>
	   <li>If the data structure  (dataset, repository, or store) is of order higher than first, 
	   then the quad pattern will be applied to the default component.
	   </li>
	 </ul>
	 <p>The solutions that are obtained by applying the QuadPattern 
	 <a href='#quad-fhir-heartrate'>QP<sub>FHIR-heartrate</sub></a> to 
	 the first-order dataset <a href='#fhir-dataset'>D<sub>FHIR</sub></a> are
	 shown in the following table, and denoted by Ω<sub>hr</sub>.
	 </p>
	 <table>
		<tr>
			<th>?g</th>
			<th>?heartRateObservation</th>
			<th>?patient</th>
			<th>?heartRate_time</th>
			<th>?heartRate</th>
		</tr>
		<tr>
			<td>_:b101</td>
			<td>_:b1</td>
			<td>lr:patientA</td>
			<td>"2015-01-01T12:00:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt;</td>
			<td>50"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt;</td>
		</tr>
		<tr>
			<td>_:b102</td>
			<td>_:b4</td>
			<td>lr:patientA</td>
			<td>"2015-01-01T12:01:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt;</td>
			<td>53"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt;</td>
		</tr>
		<tr>
			<td>_:b103</td>
			<td>_:b7</td>
			<td>lr:patientA</td>
			<td>"2015-01-01T12:02:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt;</td>
			<td>48"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt;</td>
		</tr>
		
	 </table>
We write
	 <p>Eval(D<sub>FHIR</sub>, QP<sub>FHIR-heartrate</sub>) = Ω<sub>hr</sub></p>

	 When the same QuadPattern is applied to the first-order <a>repository</a> <a href="#fhir-repository">R<sub>FHIR</sub></a>
	 we also obtain the solutions above.
	 This is because the eval function corresponds to simple entailment,
	 and simple entailment on a repository is defined as simple entailment
	 on the dataset obtained by forgetting the sequential order of versions.
	 <p>Eval(R<sub>FHIR</sub>, QP<sub>FHIR-heartrate</sub>) = Ω<sub>hr</sub></p>
	</aside>
	</section>
	<section id="ceval-examples">
	<h4>Ceval</h4>
	<p>
     A new function (Ceval) has also been defined for performing repeated (also called "continuous") matching
	 of patterns against dynamic data structures.
	 Continuous matching is "push-style" when the transmission is streamed;
	 a match event is triggered by the arrival of a stream element.
	 </p>
	<aside class="example" id="ex-continuous-match-bgp" title="Continuous Matching with a BGP">
	</aside>
	 <p  class="ednote">To be moved to the section where Ceval is defined:
	 Continuous matching is applicable to
	  <a>Repositories</a>, <a>Stores</a>,
	   sequences of <a>k-th Order RDF Datasets</a>,
	   and <a>k-th Order Sequential RDF Datasets</a>, 
	   which are structures consisting of a sequence of <a>k-th Order RDF Datasets</a>
	   and a distinguished <a>k-th Order RDF Datasets</a> called the default dataset.
     </p>
	 <p class="ednote">To define the semantics of Ceval, we need a new datatype for the result, called
	 <dfn>Structured Result</dfn>, consisting of a distinguished multiset of solution mappings, possibly empty, 
	 the default component of the structured result, and a
	 totally-ordered set of solutions (possibly empty, finite or infinite), the sequential component of the structured result.
	 </p>
	 <p class="ednote">
	 In the case that the first argument is a <a>Repository</a>, <a>Store</a>,
	 the Ceval function takes a pattern as second argument.
	 </p>
	 <p class="ednote">
	 The pattern is matched to the default component of the input data structure, 
	 to generate the default component of the <a>structured result</a>.
	 </p>
	 <p class="ednote">
	 The pattern is also matched against the union of an element of the sequence
	 together with the default component,
	 to generate the sequential part of the <a>structured result</a>.
     </p>
	 <p>The solution sequence that is obtained by matching the QuadPattern 
	 <a href='#quad-fhir-heartrate'>QP<sub>FHIR-heartrate</sub></a> continuously to 
	 the first-order repository <a href="#fhir-repository">R<sub>FHIR</sub></a> is
	 shown in the following sequence of tables, denoted by [Ω<sub>i, hr</sub>]<sub>i = 1, 2, 3</sub>.
	 </p>
	 <table>
		<tr>
			<th>?g</th>
			<th>?heartRateObservation</th>
			<th>?patient</th>
			<th>?heartRate_time</th>
			<th>?heartRate</th>
		</tr>
		<tr>
			<td>_:b101</td>
			<td>_:b1</td>
			<td>lr:patientA</td>
			<td>"2015-01-01T12:00:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt;</td>
			<td>50"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt;</td>
		</tr>
	 </table>
	 <br/><br/>
	 <table>
		<tr>
			<th>?g</th>
			<th>?heartRateObservation</th>
			<th>?patient</th>
			<th>?heartRate_time</th>
			<th>?heartRate</th>
		</tr>
		<tr>
			<td>_:b102</td>
			<td>_:b4</td>
			<td>lr:patientA</td>
			<td>"2015-01-01T12:01:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt;</td>
			<td>53"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt;</td>
		</tr>
	 </table>
	 <br/><br/>
		<table>
		<tr>
			<th>?g</th>
			<th>?heartRateObservation</th>
			<th>?patient</th>
			<th>?heartRate_time</th>
			<th>?heartRate</th>
		</tr>
		<tr>
			<td>_:b103</td>
			<td>_:b7</td>
			<td>lr:patientA</td>
			<td>"2015-01-01T12:02:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTimeStamp&gt;</td>
			<td>48"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt;</td>
		</tr>
		
	 </table>
	 <p>The Quadpattern QP<sub>FHIR-heartrate</sub> will yield no solutions
	 when matched to an RDF graph. Therefore the default component of the result is empty, no matter what
	 is in the default dataset R<sub>FHIR</sub>.
	 </p>
	 <p>We write</p>
	 <p>Ceval(R<sub>FHIR</sub>, QP<sub>FHIR-heartrate</sub>) = {} ∪ [Ω<sub>i,hr</sub>]<sub>i=1, 2, 3</sub></p>
	 as well as
	 <p>Ceval-prov(R<sub>FHIR</sub>, QP<sub>FHIR-heartrate</sub>) = {} ∪ [Ω<sub>i,hr</sub>]<sub>i=1, 2, 3</sub></p>
	 <p class="ednote">RDF Stream remarks:
	 Recall that inference on an RDF stream is supposed to be oblivious to which triple is the timestamp triple.
	 The special status of timestamp triple is supposed to only be used in windowing operations. 
	 So, a continuous query on a stream should not be able to determine which triple is the timestamp triple.
	 However, a second-order repository that emulates an RDF stream needs to keep this information somewhere,
	 for windowing purposes.
	 The default dataset of the repository is the logical place for this information to be stored. 
	 With a property "repo:hasTimestampTriple", and the RDF reification vocabulary, this
	 information can be materialized provided there is an identifier for each stream element (and this
	 identifier is an inherent part of the second-order repository).
	 Queries of the repository that are supposed to emulate queries of the stream MUST not access that information.
	 This works out OK as long as a repository is used to emulate the stream - the pattern to match against stream elements
	 must have a second-order name (i.e. it is a quint pattern) and so will give no solutions when matched against the
	 default first-order dataset.
	 </p>
	 <p class="ednote">Restrictions on the arguments of Ceval in order to emulate an unwindowed query of an RDF stream:
	 </p>
	 <ol>
	 <li>It is necessary to include the (second-order) dataset name as a variable in the query, so that 
	     the query matching is scoped to one stream element at a time. However, there needs to be a
		 Projection applied to the solution so that the dataset name is forgotten for the <a>structured result</a>
	 </li>
	 <li>Since an RDF Stream does not have a default dataset, there should be no additional entailments
	     such as those arising from the structural information of the stream, with property <code>repo:hasTimestampTriple</code>.
		 On the other hand, we want to enable queries of RDF streams jointly with static datasets.
		 The union of a static and dynamic data structure puts the static statements into the default component of the
		 dynamic structure, so the union of a static dataset and an RDF stream will have a default component (except for the trivial
		 case when the static structure is empty). For proper querying in this case, it would be helpful if in the "union" the
		 elements of sequential components are named with blank nodes, so that the result of the union is a repository.
		 On the other hand, the union of a stream with an empty static dataset causes a change of type, which is undesirable.
	</li>	 
	 </ol>
	 <p class="ednote">
	 	 Note that windowing is supposed to be performed prior to pattern matching, so if windowing is done on an RDF stream,
	 the result is a stream (sequence) of RDF Datasets, and this is not (in general) an RDF Stream.
	 So we also need to define Ceval on a sequence of (unnamed) RDF Datasets, and further, show how to
	 restrict the arguments of Ceval so that a second-order repository can be used to emulate a stream of RDF Datasets.
	 </p>
	<p class="ednote">
	 In the case that the first argument of Ceval is a <a>sequential dataset</a>,
	 the Ceval function takes a <a>k-th Order Pattern</a>, P<sub>seq</sub>, as second argument,
	 and an optional <a>k-th Order Pattern</a>, P<sub>def</sub> as third argument.
	 The pattern P<sub>seq</sub> is matched continuously against
	 the union of each element of the sequence with the default dataset,
	 to generate the sequential part of the <a>structured result</a>,
	 while the default component of the <a>structured result</a> is obtained
	 from a one-time match of P<sub>def</sub> against the default dataset.
	 </p>
	 <p class="ednote">
	 The case that the first argument is an <a>RDF Stream</a>
     is a specialization of the case that the first argument is a sequence of 
	 <a>k-th Order RDF Datasets</a>, with k = 1, with empty default dataset.
	 Therefore, the second argument P<sub>seq</sub> MUST be a Quadpattern.
	 If a third argument is present, it has no effect since the default dataset is empty.
	 </p>
	 <p class="ednote">
	 The case that the first argument is the merger or union of an <a>RDF Stream</a>
	 with a static first-order dataset
     is also a specialization of the case that the first argument is a sequence of 
	 <a>k-th Order RDF Datasets</a>, with k = 1, with non-empty default dataset.
	 Again, the second argument P<sub>seq</sub> MUST be a Quadpattern.
	 If a third argument is present, it does have an effect since the default dataset is non-empty.
	 </p>
	 <p class="ednote">This formulation of the Ceval function that takes two pattern arguments is
	 not very satisfactory because it breaks the SPARQL syntactic convention of processing just one pattern at a time.
	 It might be better to split off the matching of the pattern on the default structure to another
	 Eval spinoff, e.g. Seval - for Static evaluation on a dynamic data structure, where the pattern is matched
	 only against the default component, and the result is a single multiset of solution mappings.
	 </p>
	<p class="ednote">OK, the continuous eval function Ceval has not actually been defined yet either.
	The description above will form the basis of that definition.
	The problem is that we have proposed three different "evals" on dynamic structures, Eval, Ceval and Seval.
	To express this in the concrete syntax, we need to provide a hint as to which "eval" function is intended,
	given
	</p>
	<pre>
	SELECT *
	FROM &lt;dynamic data structure IRI&gt;
	WHERE {some pattern}
	</pre>
	<p>
	There is a choice for indicating the different kinds of eval syntactically (with reserved words) or semantically,
	with e.g. query strings.
	In the former case, the syntactic hints can be applied to construct subqueries without binding them to an IRI.
	In the latter case, IRIs become non-opaque, since the query string would be used to determine the transformation
	from concrete to abstract syntax.
	</p>
	-->
				</section>
				<section id="dataset-union-examples">
					<h4>Dataset-UNION</h4>
					<p>The Dataset-UNION basic operation has been extended to apply to arbitrary
						pairs of higher-order datasets. It has also been extended to apply to pairs
						where one of the elements is a higher-order dataset and the other is a
						dynamic data structure (repository, store, data sequence ). </p>
					<p> In all cases, the first step of evaluation is to elevate a static input
						argument as needed: to the same order (in the case of two higher-order
						datasets), or in the case of one static and one dynamic structure, to the
						requisite orders so that the default component of the dynamic structure is
						of the same order as the static structure. Then it is sufficient to consider
						input arguments where these orders are already compatible. The type of the
						result is either a dynamic structure, of the same type and order as the
						dynamic input, or a static, higher-order dataset, of the order of the two
						inputs. </p>
				</section>
			</section>
		</section>
		<section id="structural-inferences">
			<div style="text-align: left;">
				<table class="thinborder" style="margin-left: auto; margin-right: auto;">
					<caption id="structural-inferences-table"><b>Table D</b>: Inferences under the
						provenance and structural entailment regimes</caption>
					<tbody>
						<tr>
							<th><b>Structure</b></th>
							<th><b>Regime</b></th>
							<th><b>Property</b></th>
							<th><b>Usage</b>
							</th>
						</tr>
						<tr>
							<td><a>Repository</a>
								<a>Store</a></td>
							<td>provenance</td>
							<td>prov:wasRevisionOf</td>
							<td>Usage </td>
						</tr>
						<tr>
							<td><a>Repository</a>
								<a>Store</a>
							</td>
							<td>provenance</td>
							<td>repo:isInitialVersion</td>
							<td>Usage </td>
						</tr>
						<tr>
							<td><a>Repository</a>
								<a>Store</a>
							</td>
							<td>structural</td>
							<td>repo:isTerminalVersion</td>
							<td>Usage </td>
						</tr>
						<tr>
							<td><a>Named Repository</a>
							</td>
							<td>provenance</td>
							<td>prov:isSpecializationOf</td>
							<td>Usage </td>
						</tr>
						<tr>
							<td><a>Named Repository</a>
							</td>
							<td>provenance</td>
							<td>repo:isInitialVersionOf</td>
							<td>Usage </td>
						</tr>
						<tr>
							<td><a>Named Repository</a>
							</td>
							<td>structural</td>
							<td>repo:isTerminalVersionOf</td>
							<td>Usage </td>
						</tr>
					</tbody>
				</table>
			</div>
		</section>
		<!-- CONFORMANCE -->
		<section id="conformance"> </section>
	</body>
</html>
